{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c92577",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8616ccf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n",
      "Num GPUs Available:  1\n",
      "GPUs disponibles : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Version TF : 2.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import TextVectorization, Embedding, SimpleRNN, Dense, LSTM, Flatten\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing\n",
    "from mlflow import MlflowClient\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from Source.preprocess_data import *  ## import all functions from preprocess_data.py\n",
    "from Source.postprocess_data import * ## import all functions from postprocess_data.py\n",
    "from Source.utils import *  ## import all functions from utils.py\n",
    "# import nltk\n",
    "# import optuna\n",
    "# ü§ó\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "# from nltk.corpus import stopwords  \n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "nw = multiprocessing.cpu_count()\n",
    "\n",
    "\n",
    "\n",
    "client = MlflowClient(tracking_uri=\"http://localhost:8080\")\n",
    "os.environ[\"TF_KERAS\"]='1'\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPUs disponibles :\", tf.config.list_physical_devices(\"GPU\"))\n",
    "print(\"Version TF :\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788f45b2",
   "metadata": {},
   "source": [
    "# Pr√©paration data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4e0f0a",
   "metadata": {},
   "source": [
    "## Importation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "196d7d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 160000 rows\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/AI+Engineer/Project+7%C2%A0-+D%C3%A9tectez+les+Bad+Buzz+gr%C3%A2ce+au+Deep+Learning/sentiment140.zip',\n",
    "                header=None,\n",
    "                compression='zip',\n",
    "                encoding='cp1252')\n",
    "\n",
    "df.columns = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "\n",
    "sample_df, _ = train_test_split(df, test_size=0.9, random_state=42, stratify=df['target'])\n",
    "sample_df = sample_df.reset_index(drop=True)\n",
    "print(f\"Sample size: {sample_df.shape[0]} rows\")\n",
    "# On ne garde que les colonnes 'target' et 'text'\n",
    "sample_df = sample_df[['target', 'text']]\n",
    "sample_df[\"target\"] = sample_df[\"target\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "sample_df.to_csv('Data/raw_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fca7f92",
   "metadata": {},
   "source": [
    "## Train/Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c0ba358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X_raw = sample_df['text']\n",
    "y = sample_df['target']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_raw, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b8e27f",
   "metadata": {},
   "source": [
    "# Fonction centrale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ad5576",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_size = 64\n",
    "epochs = 10\n",
    "lr = 1e-3\n",
    "\n",
    "\n",
    "def test_bert_model(bert_model_name):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(params={\n",
    "            'rnn_size': rnn_size, \n",
    "            'epochs': epochs, \n",
    "            'learning_rate': lr,\n",
    "            'bert_model_name':bert_model_name\n",
    "        })\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "        encodings_train = tokenizer(X_train.to_list(), truncation=True, padding=True, return_tensors=\"tf\")\n",
    "        encodings_val = tokenizer(X_val.to_list(), truncation=True, padding=True, return_tensors=\"tf\")\n",
    "\n",
    "        dataset_train = tf.data.Dataset.from_tensor_slices(\n",
    "            (\n",
    "                {\"input_ids\": encodings_train[\"input_ids\"], \n",
    "                 \"attention_mask\": encodings_train[\"attention_mask\"]\n",
    "                 },y_train\n",
    "                )\n",
    "                ).batch(32)\n",
    "        \n",
    "        dataset_val = tf.data.Dataset.from_tensor_slices(\n",
    "            (\n",
    "                {\"input_ids\": encodings_val[\"input_ids\"], \n",
    "                 \"attention_mask\": encodings_val[\"attention_mask\"]\n",
    "                 },y_val\n",
    "                )\n",
    "                ).batch(32)\n",
    "        # On charge le mod√®le pr√©-entrainn√©\n",
    "        base_model = TFAutoModel.from_pretrained(bert_model_name, from_pt=True)\n",
    "        base_model.trainable = False # Pas de fine-tuning ou d'entrainement car impossible √† faire avec les ressources disponibles\n",
    "\n",
    "        # Construction du mod√®le keras \n",
    "        ## Une input layer pour les input ids\n",
    "        input_ids = tf.keras.Input(shape=(None,), dtype=tf.int32, name=\"input_ids\")\n",
    "        ## Une input layer pour le masque d'attention\n",
    "        attention_mask = tf.keras.Input(shape=(None,), dtype=tf.int32, name=\"attention_mask\")\n",
    "        ## On r√©cup√®re \n",
    "\n",
    "        outputs = base_model(input_ids, attention_mask=attention_mask)\n",
    "        # On prend le token [CLS] comme vecteur de phrase\n",
    "        if \"roberta\" in model_name or \"bertweet\" in model_name:\n",
    "        # Roberta / BERTweet utilisent √©galement last_hidden_state[:,0,:] pour le [CLS]\n",
    "            cls_token = outputs.last_hidden_state[:, 0, :]\n",
    "        else:\n",
    "            cls_token = outputs.last_hidden_state[:, 0, :]\n",
    "    \n",
    "        x = tf.keras.layers.Dense(rnn_size, activation=\"relu\")(cls_token)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        logits = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "        model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=logits)\n",
    "\n",
    "        ## Callbacks\n",
    "        model_savepath = f\"./Models/MY_{'_'.join(bert_model_name.split('/'))}_dense{rnn_size}.h5\"\n",
    "        checkpoint = ModelCheckpoint(model_savepath, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min')\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
    "        lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=0, min_lr=1e-5)\n",
    "        callbacks_list = [checkpoint, es, lr_scheduler]\n",
    "\n",
    "\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "        # Summary\n",
    "        model.summary()\n",
    "        # History\n",
    "        with tf.device(\"/GPU:0\"):\n",
    "            history = model.fit(dataset_train, epochs=epochs, batch_size=64, validation_data=dataset_val, callbacks=callbacks_list, verbose=1)\n",
    "\n",
    "\n",
    "        model.load_weights(model_savepath)\n",
    "\n",
    "                # Pr√©dictions sur le jeu de validation\n",
    "        y_pred_proba = model.predict(dataset_val)\n",
    "        y_pred = (y_pred_proba>0.5)\n",
    "\n",
    "\n",
    "        output_dict = postprocess_model_output(y_val, y_pred, y_pred_proba) # voir postprocess_data.py\n",
    "\n",
    "        # Logging des m√©triques dans MLflow\n",
    "        mlflow.log_metrics(output_dict)\n",
    "        # Matrice de confusion\n",
    "        cm = confusion_matrix(y_val, y_pred, normalize='pred')\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\", ax=ax, )\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.title(\"Confusion Matrix - Validation Set\")\n",
    "        fig.savefig(\"confusion_matrix.png\")\n",
    "        plt.close(fig)\n",
    "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "        #\n",
    "        fig2 = plot_training_history(history,show=False)\n",
    "        fig2.savefig(\"learning_path.png\")\n",
    "        plt.close(fig2)\n",
    "        mlflow.log_artifact(\"learning_path.png\")\n",
    "\n",
    "        # Enregistrement du mod√®le dans MLflow\n",
    "        mlflow.tensorflow.log_model(model, \"model\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b45e0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88b67ee9",
   "metadata": {},
   "source": [
    "# Experiment MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b09a8d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 366, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 464, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1634, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1627, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 366, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 464, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1634, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1627, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up MLflow experiment...\n"
     ]
    }
   ],
   "source": [
    "# Cr√©ation de l'√©tude Optuna et optimisation\n",
    "print(\"Setting up MLflow experiment...\")\n",
    "mlflow.set_experiment(\"BERT_models_experiment\")\n",
    "exp_id = mlflow.get_experiment_by_name(\"BERT_models_experiment\").experiment_id\n",
    "\n",
    "experiment_description = (\n",
    "    \"Comparaison de plusieurs mod√®les BERT\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"Sentiment analysis modelling\",\n",
    "    \"model_type\": \"BERT_pretrained\",\n",
    "    \"team\": \"Ph. Constant\",\n",
    "    \"project_quarter\": \"Q3-2025\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "for key, value in experiment_tags.items():\n",
    "    client.set_experiment_tag(exp_id, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68246c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_list = [\n",
    "    # \"prajjwal1/bert-tiny\",\n",
    "    # \"prajjwal1/bert-small\",\n",
    "    \"distilbert-base-uncased\",\n",
    "    \"roberta-base\",\n",
    "    \"distilroberta-base\",\n",
    "    \"vinai/bertweet-base\",  \n",
    "    \"finiteautomata/bertweet-base-sentiment-analysis\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c722ca",
   "metadata": {},
   "source": [
    "# Lancement experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbb5c1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 4386s 1s/step - loss: 0.5505 - accuracy: 0.7213 - val_loss: 0.4971 - val_accuracy: 0.7562 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 4593s 1s/step - loss: 0.5150 - accuracy: 0.7435 - val_loss: 0.4857 - val_accuracy: 0.7661 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 4541s 1s/step - loss: 0.5093 - accuracy: 0.7491 - val_loss: 0.4585 - val_accuracy: 0.7880 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 4549s 1s/step - loss: 0.5061 - accuracy: 0.7511 - val_loss: 0.4555 - val_accuracy: 0.7881 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 4552s 1s/step - loss: 0.5034 - accuracy: 0.7533 - val_loss: 0.4602 - val_accuracy: 0.7878 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 4332s 1s/step - loss: 0.5035 - accuracy: 0.7526 - val_loss: 0.4839 - val_accuracy: 0.7576 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 4195s 1s/step - loss: 0.4973 - accuracy: 0.7577 - val_loss: 0.4395 - val_accuracy: 0.7988 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 4253s 1s/step - loss: 0.4951 - accuracy: 0.7584 - val_loss: 0.4381 - val_accuracy: 0.8010 - lr: 5.0000e-04\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 4665s 1s/step - loss: 0.4935 - accuracy: 0.7588 - val_loss: 0.4360 - val_accuracy: 0.8003 - lr: 5.0000e-04\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 4726s 1s/step - loss: 0.4940 - accuracy: 0.7592 - val_loss: 0.4386 - val_accuracy: 0.7991 - lr: 5.0000e-04\n",
      "1000/1000 [==============================] - 523s 519ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/17 01:24:00 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/17 01:24:00 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn, pooler_layer_call_and_return_conditional_losses, embeddings_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp5sph3p35\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp5sph3p35\\model\\data\\model\\assets\n",
      "2025/09/17 01:25:28 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp5sph3p35\\model, flavor: tensorflow). Fall back to return ['tensorflow==2.10.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/09/17 01:25:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with BERT model : distilroberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\bassm\\.cache\\huggingface\\hub\\models--distilroberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " tf_roberta_model_1 (TFRobertaM  TFBaseModelOutputWi  82118400   ['input_ids[0][0]',              \n",
      " odel)                          thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, None                                               \n",
      "                                , 768),                                                           \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 768)         0           ['tf_roberta_model_1[0][0]']     \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 64)           49216       ['tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_77 (Dropout)           (None, 64)           0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            65          ['dropout_77[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 82,167,681\n",
      "Trainable params: 49,281\n",
      "Non-trainable params: 82,118,400\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 3009s 750ms/step - loss: 0.5355 - accuracy: 0.7349 - val_loss: 0.4879 - val_accuracy: 0.7637 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 3224s 806ms/step - loss: 0.5041 - accuracy: 0.7538 - val_loss: 0.4727 - val_accuracy: 0.7707 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 2870s 717ms/step - loss: 0.5008 - accuracy: 0.7559 - val_loss: 0.4717 - val_accuracy: 0.7702 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 2838s 709ms/step - loss: 0.4988 - accuracy: 0.7560 - val_loss: 0.4618 - val_accuracy: 0.7760 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 2769s 692ms/step - loss: 0.4962 - accuracy: 0.7595 - val_loss: 0.4534 - val_accuracy: 0.7851 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 2770s 693ms/step - loss: 0.4942 - accuracy: 0.7611 - val_loss: 0.4544 - val_accuracy: 0.7843 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 2816s 704ms/step - loss: 0.4924 - accuracy: 0.7615 - val_loss: 0.4490 - val_accuracy: 0.7907 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 2845s 711ms/step - loss: 0.4914 - accuracy: 0.7623 - val_loss: 0.4459 - val_accuracy: 0.7904 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 2810s 703ms/step - loss: 0.4900 - accuracy: 0.7633 - val_loss: 0.4511 - val_accuracy: 0.7859 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 2815s 704ms/step - loss: 0.4889 - accuracy: 0.7640 - val_loss: 0.4457 - val_accuracy: 0.7918 - lr: 0.0010\n",
      "1000/1000 [==============================] - 326s 324ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/17 09:32:44 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/17 09:32:44 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn, pooler_layer_call_and_return_conditional_losses, embeddings_layer_call_fn while saving (showing 5 of 216). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpwai6_fyn\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpwai6_fyn\\model\\data\\model\\assets\n",
      "2025/09/17 09:33:33 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpwai6_fyn\\model, flavor: tensorflow). Fall back to return ['tensorflow==2.10.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/09/17 09:33:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with BERT model : vinai/bertweet-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\bassm\\.cache\\huggingface\\hub\\models--vinai--bertweet-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'roberta.embeddings.position_ids', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " tf_roberta_model_2 (TFRobertaM  TFBaseModelOutputWi  134899968  ['input_ids[0][0]',              \n",
      " odel)                          thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, None                                               \n",
      "                                , 768),                                                           \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 768)         0           ['tf_roberta_model_2[0][0]']     \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 64)           49216       ['tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_115 (Dropout)          (None, 64)           0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            65          ['dropout_115[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 134,949,249\n",
      "Trainable params: 49,281\n",
      "Non-trainable params: 134,899,968\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 1215s 302ms/step - loss: 0.5507 - accuracy: 0.7156 - val_loss: 0.4853 - val_accuracy: 0.7707 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1251s 313ms/step - loss: 0.5226 - accuracy: 0.7378 - val_loss: 0.4695 - val_accuracy: 0.7775 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1534s 383ms/step - loss: 0.5145 - accuracy: 0.7445 - val_loss: 0.4699 - val_accuracy: 0.7749 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1542s 385ms/step - loss: 0.5112 - accuracy: 0.7470 - val_loss: 0.4868 - val_accuracy: 0.7541 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1546s 387ms/step - loss: 0.5010 - accuracy: 0.7541 - val_loss: 0.4531 - val_accuracy: 0.7888 - lr: 5.0000e-04\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1541s 385ms/step - loss: 0.5003 - accuracy: 0.7555 - val_loss: 0.4598 - val_accuracy: 0.7814 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1545s 386ms/step - loss: 0.4980 - accuracy: 0.7544 - val_loss: 0.4461 - val_accuracy: 0.7988 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1549s 387ms/step - loss: 0.4970 - accuracy: 0.7570 - val_loss: 0.4433 - val_accuracy: 0.7982 - lr: 5.0000e-04\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1538s 384ms/step - loss: 0.4961 - accuracy: 0.7568 - val_loss: 0.4460 - val_accuracy: 0.7972 - lr: 5.0000e-04\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1542s 385ms/step - loss: 0.4951 - accuracy: 0.7575 - val_loss: 0.4420 - val_accuracy: 0.7952 - lr: 5.0000e-04\n",
      "1000/1000 [==============================] - 293s 289ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/17 13:48:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/17 13:48:01 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn, pooler_layer_call_and_return_conditional_losses, embeddings_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmph91c2h9a\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmph91c2h9a\\model\\data\\model\\assets\n",
      "2025/09/17 13:49:23 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmph91c2h9a\\model, flavor: tensorflow). Fall back to return ['tensorflow==2.10.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/09/17 13:49:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with BERT model : finiteautomata/bertweet-base-sentiment-analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\bassm\\.cache\\huggingface\\hub\\models--finiteautomata--bertweet-base-sentiment-analysis. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['roberta.embeddings.position_ids', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " tf_roberta_model_3 (TFRobertaM  TFBaseModelOutputWi  134899968  ['input_ids[0][0]',              \n",
      " odel)                          thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, None                                               \n",
      "                                , 768),                                                           \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_4 (Sl  (None, 768)         0           ['tf_roberta_model_3[0][0]']     \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 64)           49216       ['tf.__operators__.getitem_4[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_153 (Dropout)          (None, 64)           0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 1)            65          ['dropout_153[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 134,949,249\n",
      "Trainable params: 49,281\n",
      "Non-trainable params: 134,899,968\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 1538s 382ms/step - loss: 0.4068 - accuracy: 0.8190 - val_loss: 0.3813 - val_accuracy: 0.8311 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1530s 382ms/step - loss: 0.3917 - accuracy: 0.8269 - val_loss: 0.3783 - val_accuracy: 0.8329 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1534s 384ms/step - loss: 0.3890 - accuracy: 0.8276 - val_loss: 0.3733 - val_accuracy: 0.8341 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1535s 384ms/step - loss: 0.3869 - accuracy: 0.8287 - val_loss: 0.3703 - val_accuracy: 0.8363 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1432s 358ms/step - loss: 0.3851 - accuracy: 0.8295 - val_loss: 0.3712 - val_accuracy: 0.8367 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1390s 348ms/step - loss: 0.3831 - accuracy: 0.8313 - val_loss: 0.3708 - val_accuracy: 0.8371 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1428s 357ms/step - loss: 0.3799 - accuracy: 0.8323 - val_loss: 0.3653 - val_accuracy: 0.8394 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1402s 351ms/step - loss: 0.3787 - accuracy: 0.8326 - val_loss: 0.3645 - val_accuracy: 0.8399 - lr: 5.0000e-04\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1384s 346ms/step - loss: 0.3781 - accuracy: 0.8330 - val_loss: 0.3645 - val_accuracy: 0.8397 - lr: 5.0000e-04\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1599s 400ms/step - loss: 0.3776 - accuracy: 0.8334 - val_loss: 0.3628 - val_accuracy: 0.8401 - lr: 5.0000e-04\n",
      "1000/1000 [==============================] - 268s 264ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/17 18:02:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/17 18:02:02 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn, pooler_layer_call_and_return_conditional_losses, embeddings_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpcu7ge4yc\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpcu7ge4yc\\model\\data\\model\\assets\n",
      "2025/09/17 18:03:56 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpcu7ge4yc\\model, flavor: tensorflow). Fall back to return ['tensorflow==2.10.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/09/17 18:03:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "for model_name in bert_model_list:\n",
    "    print(f\"Running test with BERT model : {model_name}\")\n",
    "    test_bert_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a48d89",
   "metadata": {},
   "source": [
    "# Optimisation de la t√™te du mod√®le (plus petit dataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b75d69",
   "metadata": {},
   "source": [
    "## R√©duction du dataset d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c515d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 16000 rows\n"
     ]
    }
   ],
   "source": [
    "sample_df, _ = train_test_split(df, test_size=0.99, random_state=42, stratify=df['target'])\n",
    "sample_df = sample_df.reset_index(drop=True)\n",
    "print(f\"Sample size: {sample_df.shape[0]} rows\")\n",
    "# On ne garde que les colonnes 'target' et 'text'\n",
    "sample_df = sample_df[['target', 'text']]\n",
    "sample_df[\"target\"] = sample_df[\"target\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "sample_df.to_csv('Data/raw_data_mini.csv', index=False)\n",
    "\n",
    "# Data\n",
    "X_raw = sample_df['text']\n",
    "y = sample_df['target']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_raw, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a946834",
   "metadata": {},
   "source": [
    "Fonction de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcc87c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "lr = 1e-3\n",
    "\n",
    "\n",
    "def test_bert_model_v2(bert_model_name, rnn_size):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(params={\n",
    "            'rnn_size': rnn_size, \n",
    "            'epochs': epochs, \n",
    "            'learning_rate': lr,\n",
    "            'bert_model_name':bert_model_name\n",
    "        })\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "        encodings_train = tokenizer(X_train.to_list(), truncation=True, padding=True, return_tensors=\"tf\")\n",
    "        encodings_val = tokenizer(X_val.to_list(), truncation=True, padding=True, return_tensors=\"tf\")\n",
    "\n",
    "        dataset_train = tf.data.Dataset.from_tensor_slices(\n",
    "            (\n",
    "                {\"input_ids\": encodings_train[\"input_ids\"], \n",
    "                 \"attention_mask\": encodings_train[\"attention_mask\"]\n",
    "                 },y_train\n",
    "                )\n",
    "                ).batch(32)\n",
    "        \n",
    "        dataset_val = tf.data.Dataset.from_tensor_slices(\n",
    "            (\n",
    "                {\"input_ids\": encodings_val[\"input_ids\"], \n",
    "                 \"attention_mask\": encodings_val[\"attention_mask\"]\n",
    "                 },y_val\n",
    "                )\n",
    "                ).batch(32)\n",
    "        # On charge le mod√®le pr√©-entrainn√©\n",
    "        base_model = TFAutoModel.from_pretrained(bert_model_name, from_pt=True)\n",
    "        base_model.trainable = False # Pas de fine-tuning ou d'entrainement car impossible √† faire avec les ressources disponibles\n",
    "\n",
    "        # Construction du mod√®le keras \n",
    "        ## Une input layer pour les input ids\n",
    "        input_ids = tf.keras.Input(shape=(None,), dtype=tf.int32, name=\"input_ids\")\n",
    "        ## Une input layer pour le masque d'attention\n",
    "        attention_mask = tf.keras.Input(shape=(None,), dtype=tf.int32, name=\"attention_mask\")\n",
    "        ## On r√©cup√®re \n",
    "\n",
    "        outputs = base_model(input_ids, attention_mask=attention_mask)\n",
    "        # On prend le token [CLS] comme vecteur de phrase\n",
    "        if \"roberta\" in model_name or \"bertweet\" in model_name:\n",
    "        # Roberta / BERTweet utilisent √©galement last_hidden_state[:,0,:] pour le [CLS]\n",
    "            cls_token = outputs.last_hidden_state[:, 0, :]\n",
    "        else:\n",
    "            cls_token = outputs.last_hidden_state[:, 0, :]\n",
    "    \n",
    "        x = tf.keras.layers.Dense(rnn_size, activation=\"relu\")(cls_token)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "        logits = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "        model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=logits)\n",
    "\n",
    "        ## Callbacks\n",
    "        model_savepath = f\"./Models/MY_{'_'.join(bert_model_name.split('/'))}_dense{rnn_size}.h5\"\n",
    "        checkpoint = ModelCheckpoint(model_savepath, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min')\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
    "        lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=0, min_lr=1e-5)\n",
    "        callbacks_list = [checkpoint, es, lr_scheduler]\n",
    "\n",
    "\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "        # Summary\n",
    "        model.summary()\n",
    "        # History\n",
    "        with tf.device(\"/GPU:0\"):\n",
    "            history = model.fit(dataset_train, epochs=epochs, batch_size=64, validation_data=dataset_val, callbacks=callbacks_list, verbose=1)\n",
    "\n",
    "\n",
    "        model.load_weights(model_savepath)\n",
    "\n",
    "                # Pr√©dictions sur le jeu de validation\n",
    "        y_pred_proba = model.predict(dataset_val)\n",
    "        y_pred = (y_pred_proba>0.5)\n",
    "\n",
    "\n",
    "        output_dict = postprocess_model_output(y_val, y_pred, y_pred_proba) # voir postprocess_data.py\n",
    "\n",
    "        # Logging des m√©triques dans MLflow\n",
    "        mlflow.log_metrics(output_dict)\n",
    "        # Matrice de confusion\n",
    "        cm = confusion_matrix(y_val, y_pred, normalize='pred')\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\", ax=ax, )\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.title(\"Confusion Matrix - Validation Set\")\n",
    "        fig.savefig(\"confusion_matrix.png\")\n",
    "        plt.close(fig)\n",
    "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "        #\n",
    "        fig2 = plot_training_history(history,show=False)\n",
    "        fig2.savefig(\"learning_path.png\")\n",
    "        plt.close(fig2)\n",
    "        mlflow.log_artifact(\"learning_path.png\")\n",
    "\n",
    "        # Enregistrement du mod√®le dans MLflow\n",
    "        mlflow.tensorflow.log_model(model, \"model\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71b98277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up MLflow experiment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 366, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 464, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1634, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1627, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 366, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 464, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1634, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1627, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n"
     ]
    }
   ],
   "source": [
    "# Cr√©ation de l'√©tude Optuna et optimisation\n",
    "print(\"Setting up MLflow experiment...\")\n",
    "mlflow.set_experiment(\"BERT_models_experiment\")\n",
    "exp_id = mlflow.get_experiment_by_name(\"BERT_models_experiment\").experiment_id\n",
    "\n",
    "experiment_description = (\n",
    "    \"Optimisation de la t√™te du mod√®le bas√© sur BERT.\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"Sentiment analysis modelling\",\n",
    "    \"model_type\": \"BERT_pretrained\",\n",
    "    \"team\": \"Ph. Constant\",\n",
    "    \"project_quarter\": \"Q3-2025\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "for key, value in experiment_tags.items():\n",
    "    client.set_experiment_tag(exp_id, key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d4578",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f39cadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 149s 373ms/step - loss: 0.3990 - accuracy: 0.8241 - val_loss: 0.3833 - val_accuracy: 0.8316 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 160s 400ms/step - loss: 0.3953 - accuracy: 0.8236 - val_loss: 0.3844 - val_accuracy: 0.8328 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 171s 428ms/step - loss: 0.3933 - accuracy: 0.8272 - val_loss: 0.3778 - val_accuracy: 0.8322 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 151s 377ms/step - loss: 0.3894 - accuracy: 0.8284 - val_loss: 0.3820 - val_accuracy: 0.8359 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 152s 380ms/step - loss: 0.3872 - accuracy: 0.8291 - val_loss: 0.3814 - val_accuracy: 0.8328 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 166s 416ms/step - loss: 0.3829 - accuracy: 0.8285 - val_loss: 0.3745 - val_accuracy: 0.8366 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 159s 397ms/step - loss: 0.3810 - accuracy: 0.8336 - val_loss: 0.3747 - val_accuracy: 0.8381 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 159s 397ms/step - loss: 0.3800 - accuracy: 0.8314 - val_loss: 0.3746 - val_accuracy: 0.8375 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 160s 400ms/step - loss: 0.3728 - accuracy: 0.8351 - val_loss: 0.3750 - val_accuracy: 0.8397 - lr: 2.5000e-04\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 158s 396ms/step - loss: 0.3687 - accuracy: 0.8374 - val_loss: 0.3758 - val_accuracy: 0.8388 - lr: 2.5000e-04\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 159s 396ms/step - loss: 0.3677 - accuracy: 0.8385 - val_loss: 0.3753 - val_accuracy: 0.8391 - lr: 1.2500e-04\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 168s 420ms/step - loss: 0.3709 - accuracy: 0.8352 - val_loss: 0.3739 - val_accuracy: 0.8409 - lr: 1.2500e-04\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 167s 417ms/step - loss: 0.3686 - accuracy: 0.8372 - val_loss: 0.3736 - val_accuracy: 0.8400 - lr: 1.2500e-04\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 129s 323ms/step - loss: 0.3711 - accuracy: 0.8333 - val_loss: 0.3732 - val_accuracy: 0.8403 - lr: 1.2500e-04\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 119s 298ms/step - loss: 0.3711 - accuracy: 0.8377 - val_loss: 0.3740 - val_accuracy: 0.8400 - lr: 1.2500e-04\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 124s 309ms/step - loss: 0.3696 - accuracy: 0.8383 - val_loss: 0.3746 - val_accuracy: 0.8372 - lr: 1.2500e-04\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 127s 317ms/step - loss: 0.3660 - accuracy: 0.8355 - val_loss: 0.3737 - val_accuracy: 0.8406 - lr: 6.2500e-05\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 139s 347ms/step - loss: 0.3661 - accuracy: 0.8359 - val_loss: 0.3741 - val_accuracy: 0.8397 - lr: 6.2500e-05\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 144s 359ms/step - loss: 0.3655 - accuracy: 0.8392 - val_loss: 0.3749 - val_accuracy: 0.8397 - lr: 3.1250e-05\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 147s 367ms/step - loss: 0.3647 - accuracy: 0.8366 - val_loss: 0.3744 - val_accuracy: 0.8384 - lr: 3.1250e-05\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 144s 359ms/step - loss: 0.3620 - accuracy: 0.8393 - val_loss: 0.3745 - val_accuracy: 0.8394 - lr: 1.5625e-05\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 133s 333ms/step - loss: 0.3657 - accuracy: 0.8397 - val_loss: 0.3750 - val_accuracy: 0.8391 - lr: 1.5625e-05\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 141s 353ms/step - loss: 0.3623 - accuracy: 0.8411 - val_loss: 0.3754 - val_accuracy: 0.8388 - lr: 1.0000e-05\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 149s 373ms/step - loss: 0.3630 - accuracy: 0.8390 - val_loss: 0.3750 - val_accuracy: 0.8400 - lr: 1.0000e-05\n",
      "100/100 [==============================] - 25s 210ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/18 00:35:23 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/18 00:35:23 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn, pooler_layer_call_and_return_conditional_losses, embeddings_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpyl_jlx48\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpyl_jlx48\\model\\data\\model\\assets\n",
      "2025/09/18 00:36:51 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpyl_jlx48\\model, flavor: tensorflow). Fall back to return ['tensorflow==2.10.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/09/18 00:36:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with BERT model finiteautomata/bertweet-base-sentiment-analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['roberta.embeddings.position_ids', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " tf_roberta_model_9 (TFRobertaM  TFBaseModelOutputWi  134899968  ['input_ids[0][0]',              \n",
      " odel)                          thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, None                                               \n",
      "                                , 768),                                                           \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_10 (S  (None, 768)         0           ['tf_roberta_model_9[0][0]']     \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 192)          147648      ['tf.__operators__.getitem_10[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_381 (Dropout)          (None, 192)          0           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 1)            193         ['dropout_381[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 135,047,809\n",
      "Trainable params: 147,841\n",
      "Non-trainable params: 134,899,968\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 143s 338ms/step - loss: 0.4348 - accuracy: 0.8069 - val_loss: 0.3928 - val_accuracy: 0.8194 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 157s 393ms/step - loss: 0.4118 - accuracy: 0.8171 - val_loss: 0.3874 - val_accuracy: 0.8247 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 160s 399ms/step - loss: 0.4011 - accuracy: 0.8220 - val_loss: 0.3857 - val_accuracy: 0.8319 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 161s 404ms/step - loss: 0.3969 - accuracy: 0.8243 - val_loss: 0.3807 - val_accuracy: 0.8291 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 158s 394ms/step - loss: 0.3955 - accuracy: 0.8255 - val_loss: 0.3790 - val_accuracy: 0.8322 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 144s 359ms/step - loss: 0.3957 - accuracy: 0.8253 - val_loss: 0.3808 - val_accuracy: 0.8319 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 154s 385ms/step - loss: 0.3903 - accuracy: 0.8285 - val_loss: 0.3780 - val_accuracy: 0.8338 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 155s 388ms/step - loss: 0.3875 - accuracy: 0.8290 - val_loss: 0.3748 - val_accuracy: 0.8359 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 147s 367ms/step - loss: 0.3854 - accuracy: 0.8281 - val_loss: 0.3772 - val_accuracy: 0.8350 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 146s 364ms/step - loss: 0.3851 - accuracy: 0.8313 - val_loss: 0.3789 - val_accuracy: 0.8325 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 154s 386ms/step - loss: 0.3779 - accuracy: 0.8322 - val_loss: 0.3742 - val_accuracy: 0.8375 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 145s 364ms/step - loss: 0.3735 - accuracy: 0.8366 - val_loss: 0.3758 - val_accuracy: 0.8350 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 138s 344ms/step - loss: 0.3782 - accuracy: 0.8334 - val_loss: 0.3739 - val_accuracy: 0.8400 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 129s 323ms/step - loss: 0.3734 - accuracy: 0.8338 - val_loss: 0.3737 - val_accuracy: 0.8406 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 123s 308ms/step - loss: 0.3749 - accuracy: 0.8348 - val_loss: 0.3755 - val_accuracy: 0.8406 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 116s 290ms/step - loss: 0.3721 - accuracy: 0.8363 - val_loss: 0.3767 - val_accuracy: 0.8356 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 115s 288ms/step - loss: 0.3698 - accuracy: 0.8344 - val_loss: 0.3751 - val_accuracy: 0.8394 - lr: 2.5000e-04\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 115s 289ms/step - loss: 0.3635 - accuracy: 0.8380 - val_loss: 0.3756 - val_accuracy: 0.8403 - lr: 2.5000e-04\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 116s 290ms/step - loss: 0.3644 - accuracy: 0.8394 - val_loss: 0.3749 - val_accuracy: 0.8400 - lr: 1.2500e-04\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 116s 289ms/step - loss: 0.3627 - accuracy: 0.8389 - val_loss: 0.3760 - val_accuracy: 0.8403 - lr: 1.2500e-04\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 116s 290ms/step - loss: 0.3659 - accuracy: 0.8385 - val_loss: 0.3756 - val_accuracy: 0.8394 - lr: 6.2500e-05\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 116s 290ms/step - loss: 0.3581 - accuracy: 0.8423 - val_loss: 0.3749 - val_accuracy: 0.8397 - lr: 6.2500e-05\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 116s 290ms/step - loss: 0.3627 - accuracy: 0.8398 - val_loss: 0.3751 - val_accuracy: 0.8409 - lr: 3.1250e-05\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 115s 288ms/step - loss: 0.3629 - accuracy: 0.8388 - val_loss: 0.3760 - val_accuracy: 0.8409 - lr: 3.1250e-05\n",
      "100/100 [==============================] - 20s 167ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/18 01:31:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/18 01:31:49 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn, pooler_layer_call_and_return_conditional_losses, embeddings_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpjke54097\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpjke54097\\model\\data\\model\\assets\n",
      "2025/09/18 01:33:03 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpjke54097\\model, flavor: tensorflow). Fall back to return ['tensorflow==2.10.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/09/18 01:33:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with BERT model finiteautomata/bertweet-base-sentiment-analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['roberta.embeddings.position_ids', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " tf_roberta_model_10 (TFRoberta  TFBaseModelOutputWi  134899968  ['input_ids[0][0]',              \n",
      " Model)                         thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, None                                               \n",
      "                                , 768),                                                           \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_11 (S  (None, 768)         0           ['tf_roberta_model_10[0][0]']    \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 224)          172256      ['tf.__operators__.getitem_11[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_419 (Dropout)          (None, 224)          0           ['dense_22[0][0]']               \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 1)            225         ['dropout_419[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 135,072,449\n",
      "Trainable params: 172,481\n",
      "Non-trainable params: 134,899,968\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 130s 302ms/step - loss: 0.4310 - accuracy: 0.8083 - val_loss: 0.3923 - val_accuracy: 0.8281 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 126s 315ms/step - loss: 0.4109 - accuracy: 0.8180 - val_loss: 0.3898 - val_accuracy: 0.8263 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 126s 315ms/step - loss: 0.4040 - accuracy: 0.8201 - val_loss: 0.3853 - val_accuracy: 0.8291 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 126s 315ms/step - loss: 0.3965 - accuracy: 0.8222 - val_loss: 0.3833 - val_accuracy: 0.8316 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 126s 315ms/step - loss: 0.3939 - accuracy: 0.8243 - val_loss: 0.3827 - val_accuracy: 0.8341 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 127s 316ms/step - loss: 0.3936 - accuracy: 0.8259 - val_loss: 0.3810 - val_accuracy: 0.8325 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 126s 315ms/step - loss: 0.3913 - accuracy: 0.8273 - val_loss: 0.3775 - val_accuracy: 0.8359 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 117s 293ms/step - loss: 0.3881 - accuracy: 0.8305 - val_loss: 0.3785 - val_accuracy: 0.8331 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 117s 293ms/step - loss: 0.3855 - accuracy: 0.8291 - val_loss: 0.3797 - val_accuracy: 0.8350 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 126s 314ms/step - loss: 0.3791 - accuracy: 0.8313 - val_loss: 0.3766 - val_accuracy: 0.8359 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 126s 315ms/step - loss: 0.3799 - accuracy: 0.8321 - val_loss: 0.3742 - val_accuracy: 0.8397 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 126s 316ms/step - loss: 0.3759 - accuracy: 0.8352 - val_loss: 0.3729 - val_accuracy: 0.8353 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 126s 315ms/step - loss: 0.3740 - accuracy: 0.8334 - val_loss: 0.3721 - val_accuracy: 0.8403 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 117s 292ms/step - loss: 0.3736 - accuracy: 0.8347 - val_loss: 0.3742 - val_accuracy: 0.8388 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 117s 293ms/step - loss: 0.3712 - accuracy: 0.8351 - val_loss: 0.3746 - val_accuracy: 0.8388 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 117s 292ms/step - loss: 0.3686 - accuracy: 0.8372 - val_loss: 0.3746 - val_accuracy: 0.8378 - lr: 2.5000e-04\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 117s 293ms/step - loss: 0.3666 - accuracy: 0.8370 - val_loss: 0.3757 - val_accuracy: 0.8372 - lr: 2.5000e-04\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 117s 293ms/step - loss: 0.3629 - accuracy: 0.8405 - val_loss: 0.3732 - val_accuracy: 0.8403 - lr: 1.2500e-04\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 117s 292ms/step - loss: 0.3639 - accuracy: 0.8415 - val_loss: 0.3727 - val_accuracy: 0.8406 - lr: 1.2500e-04\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 117s 293ms/step - loss: 0.3603 - accuracy: 0.8400 - val_loss: 0.3728 - val_accuracy: 0.8425 - lr: 6.2500e-05\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 117s 293ms/step - loss: 0.3614 - accuracy: 0.8396 - val_loss: 0.3732 - val_accuracy: 0.8434 - lr: 6.2500e-05\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 117s 293ms/step - loss: 0.3588 - accuracy: 0.8420 - val_loss: 0.3735 - val_accuracy: 0.8438 - lr: 3.1250e-05\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 117s 294ms/step - loss: 0.3621 - accuracy: 0.8384 - val_loss: 0.3731 - val_accuracy: 0.8425 - lr: 3.1250e-05\n",
      "100/100 [==============================] - 20s 170ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/18 02:20:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/18 02:20:18 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn, pooler_layer_call_and_return_conditional_losses, embeddings_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpegeo4fuj\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpegeo4fuj\\model\\data\\model\\assets\n",
      "2025/09/18 02:21:34 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpegeo4fuj\\model, flavor: tensorflow). Fall back to return ['tensorflow==2.10.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/09/18 02:21:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with BERT model finiteautomata/bertweet-base-sentiment-analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['roberta.embeddings.position_ids', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " tf_roberta_model_11 (TFRoberta  TFBaseModelOutputWi  134899968  ['input_ids[0][0]',              \n",
      " Model)                         thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, None                                               \n",
      "                                , 768),                                                           \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_12 (S  (None, 768)         0           ['tf_roberta_model_11[0][0]']    \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 256)          196864      ['tf.__operators__.getitem_12[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dropout_457 (Dropout)          (None, 256)          0           ['dense_24[0][0]']               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 1)            257         ['dropout_457[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 135,097,089\n",
      "Trainable params: 197,121\n",
      "Non-trainable params: 134,899,968\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 129s 299ms/step - loss: 0.4333 - accuracy: 0.8060 - val_loss: 0.3947 - val_accuracy: 0.8250 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 125s 313ms/step - loss: 0.4129 - accuracy: 0.8166 - val_loss: 0.3847 - val_accuracy: 0.8284 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 125s 313ms/step - loss: 0.4059 - accuracy: 0.8213 - val_loss: 0.3842 - val_accuracy: 0.8297 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 125s 313ms/step - loss: 0.4004 - accuracy: 0.8229 - val_loss: 0.3811 - val_accuracy: 0.8322 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 125s 313ms/step - loss: 0.3970 - accuracy: 0.8259 - val_loss: 0.3797 - val_accuracy: 0.8338 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 117s 291ms/step - loss: 0.3931 - accuracy: 0.8283 - val_loss: 0.3855 - val_accuracy: 0.8303 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 125s 312ms/step - loss: 0.3926 - accuracy: 0.8267 - val_loss: 0.3760 - val_accuracy: 0.8363 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 116s 290ms/step - loss: 0.3903 - accuracy: 0.8276 - val_loss: 0.3793 - val_accuracy: 0.8347 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 116s 291ms/step - loss: 0.3839 - accuracy: 0.8286 - val_loss: 0.3802 - val_accuracy: 0.8328 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 125s 312ms/step - loss: 0.3769 - accuracy: 0.8315 - val_loss: 0.3747 - val_accuracy: 0.8378 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 126s 313ms/step - loss: 0.3800 - accuracy: 0.8360 - val_loss: 0.3733 - val_accuracy: 0.8391 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 116s 290ms/step - loss: 0.3784 - accuracy: 0.8314 - val_loss: 0.3754 - val_accuracy: 0.8375 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 116s 290ms/step - loss: 0.3720 - accuracy: 0.8342 - val_loss: 0.3813 - val_accuracy: 0.8350 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 116s 290ms/step - loss: 0.3701 - accuracy: 0.8367 - val_loss: 0.3761 - val_accuracy: 0.8369 - lr: 2.5000e-04\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 116s 291ms/step - loss: 0.3676 - accuracy: 0.8393 - val_loss: 0.3746 - val_accuracy: 0.8375 - lr: 2.5000e-04\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 116s 291ms/step - loss: 0.3637 - accuracy: 0.8385 - val_loss: 0.3747 - val_accuracy: 0.8384 - lr: 1.2500e-04\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 116s 291ms/step - loss: 0.3633 - accuracy: 0.8403 - val_loss: 0.3746 - val_accuracy: 0.8384 - lr: 1.2500e-04\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 116s 291ms/step - loss: 0.3622 - accuracy: 0.8410 - val_loss: 0.3738 - val_accuracy: 0.8384 - lr: 6.2500e-05\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 116s 291ms/step - loss: 0.3630 - accuracy: 0.8371 - val_loss: 0.3741 - val_accuracy: 0.8381 - lr: 6.2500e-05\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 116s 289ms/step - loss: 0.3643 - accuracy: 0.8391 - val_loss: 0.3751 - val_accuracy: 0.8388 - lr: 3.1250e-05\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 115s 289ms/step - loss: 0.3622 - accuracy: 0.8391 - val_loss: 0.3751 - val_accuracy: 0.8391 - lr: 3.1250e-05\n",
      "100/100 [==============================] - 20s 167ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/18 03:04:12 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/18 03:04:12 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn, pooler_layer_call_and_return_conditional_losses, embeddings_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpq936dckt\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpq936dckt\\model\\data\\model\\assets\n",
      "2025/09/18 03:05:24 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpq936dckt\\model, flavor: tensorflow). Fall back to return ['tensorflow==2.10.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/09/18 03:05:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "for rnn_size in list(range(64,254,64)):\n",
    "    print(f\"Running test with BERT model finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "    test_bert_model_v2(bert_model_name=\"finiteautomata/bertweet-base-sentiment-analysis\", rnn_size=rnn_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ada447",
   "metadata": {},
   "source": [
    "# Mod√®le Bert automatique depuis Huggingface \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42a860e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading file vocab.txt from cache at C:\\Users\\bassm/.cache\\huggingface\\hub\\models--finiteautomata--bertweet-base-sentiment-analysis\\snapshots\\924fc4c80bccb8003d21fe84dd92c7887717f245\\vocab.txt\n",
      "loading file bpe.codes from cache at C:\\Users\\bassm/.cache\\huggingface\\hub\\models--finiteautomata--bertweet-base-sentiment-analysis\\snapshots\\924fc4c80bccb8003d21fe84dd92c7887717f245\\bpe.codes\n",
      "loading file added_tokens.json from cache at C:\\Users\\bassm/.cache\\huggingface\\hub\\models--finiteautomata--bertweet-base-sentiment-analysis\\snapshots\\924fc4c80bccb8003d21fe84dd92c7887717f245\\added_tokens.json\n",
      "loading file special_tokens_map.json from cache at C:\\Users\\bassm/.cache\\huggingface\\hub\\models--finiteautomata--bertweet-base-sentiment-analysis\\snapshots\\924fc4c80bccb8003d21fe84dd92c7887717f245\\special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\bassm/.cache\\huggingface\\hub\\models--finiteautomata--bertweet-base-sentiment-analysis\\snapshots\\924fc4c80bccb8003d21fe84dd92c7887717f245\\tokenizer_config.json\n",
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "Adding <mask> to the vocabulary\n",
      "loading configuration file config.json from cache at C:\\Users\\bassm/.cache\\huggingface\\hub\\models--finiteautomata--bertweet-base-sentiment-analysis\\snapshots\\924fc4c80bccb8003d21fe84dd92c7887717f245\\config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"finiteautomata/bertweet-base-sentiment-analysis\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.4\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "loading weights file tf_model.h5 from cache at C:\\Users\\bassm/.cache\\huggingface\\hub\\models--finiteautomata--bertweet-base-sentiment-analysis\\snapshots\\924fc4c80bccb8003d21fe84dd92c7887717f245\\tf_model.h5\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some weights of TFRobertaForSequenceClassification were not initialized from the model checkpoint at finiteautomata/bertweet-base-sentiment-analysis and are newly initialized because the shapes did not match:\n",
      "- classifier/out_proj/kernel:0: found shape (768, 3) in the checkpoint and (768, 2) in the model instantiated\n",
      "- classifier/out_proj/bias:0: found shape (3,) in the checkpoint and (2,) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_roberta_for_sequence_classification_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " roberta (TFRobertaMainLayer  multiple                 134309376 \n",
      " )                                                               \n",
      "                                                                 \n",
      " classifier (TFRobertaClassi  multiple                 592130    \n",
      " ficationHead)                                                   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,901,506\n",
      "Trainable params: 592,130\n",
      "Non-trainable params: 134,309,376\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 165s 388ms/step - loss: 0.4843 - accuracy: 0.7817 - val_loss: 0.4481 - val_accuracy: 0.8003 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 140s 350ms/step - loss: 0.4605 - accuracy: 0.7930 - val_loss: 0.4335 - val_accuracy: 0.8078 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 131s 327ms/step - loss: 0.4538 - accuracy: 0.7980 - val_loss: 0.4395 - val_accuracy: 0.8028 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 145s 363ms/step - loss: 0.4557 - accuracy: 0.7930 - val_loss: 0.4274 - val_accuracy: 0.8103 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 151s 377ms/step - loss: 0.4518 - accuracy: 0.7991 - val_loss: 0.4263 - val_accuracy: 0.8078 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 146s 365ms/step - loss: 0.4492 - accuracy: 0.7973 - val_loss: 0.4243 - val_accuracy: 0.8097 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 145s 363ms/step - loss: 0.4466 - accuracy: 0.7994 - val_loss: 0.4201 - val_accuracy: 0.8103 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 133s 332ms/step - loss: 0.4455 - accuracy: 0.7988 - val_loss: 0.4252 - val_accuracy: 0.8037 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 131s 327ms/step - loss: 0.4448 - accuracy: 0.8030 - val_loss: 0.4226 - val_accuracy: 0.8078 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 140s 350ms/step - loss: 0.4347 - accuracy: 0.8068 - val_loss: 0.4161 - val_accuracy: 0.8078 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 146s 366ms/step - loss: 0.4332 - accuracy: 0.8064 - val_loss: 0.4136 - val_accuracy: 0.8066 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 144s 360ms/step - loss: 0.4367 - accuracy: 0.8079 - val_loss: 0.4126 - val_accuracy: 0.8091 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 131s 327ms/step - loss: 0.4304 - accuracy: 0.8080 - val_loss: 0.4183 - val_accuracy: 0.8050 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 135s 338ms/step - loss: 0.4332 - accuracy: 0.8064 - val_loss: 0.4162 - val_accuracy: 0.8078 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 130s 326ms/step - loss: 0.4289 - accuracy: 0.8095 - val_loss: 0.4149 - val_accuracy: 0.8056 - lr: 2.5000e-04\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 131s 327ms/step - loss: 0.4276 - accuracy: 0.8084 - val_loss: 0.4128 - val_accuracy: 0.8091 - lr: 2.5000e-04\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 134s 334ms/step - loss: 0.4256 - accuracy: 0.8091 - val_loss: 0.4127 - val_accuracy: 0.8094 - lr: 1.2500e-04\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 139s 349ms/step - loss: 0.4243 - accuracy: 0.8120 - val_loss: 0.4114 - val_accuracy: 0.8084 - lr: 1.2500e-04\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 131s 328ms/step - loss: 0.4232 - accuracy: 0.8104 - val_loss: 0.4115 - val_accuracy: 0.8087 - lr: 1.2500e-04\n",
      "Epoch 20/50\n",
      "400/400 [==============================] - 134s 336ms/step - loss: 0.4266 - accuracy: 0.8084 - val_loss: 0.4145 - val_accuracy: 0.8078 - lr: 1.2500e-04\n",
      "Epoch 21/50\n",
      "400/400 [==============================] - 134s 336ms/step - loss: 0.4257 - accuracy: 0.8069 - val_loss: 0.4128 - val_accuracy: 0.8081 - lr: 6.2500e-05\n",
      "Epoch 22/50\n",
      "400/400 [==============================] - 135s 338ms/step - loss: 0.4258 - accuracy: 0.8099 - val_loss: 0.4122 - val_accuracy: 0.8087 - lr: 6.2500e-05\n",
      "Epoch 23/50\n",
      "400/400 [==============================] - 139s 348ms/step - loss: 0.4270 - accuracy: 0.8094 - val_loss: 0.4121 - val_accuracy: 0.8081 - lr: 3.1250e-05\n",
      "Epoch 24/50\n",
      "400/400 [==============================] - 144s 361ms/step - loss: 0.4232 - accuracy: 0.8106 - val_loss: 0.4129 - val_accuracy: 0.8072 - lr: 3.1250e-05\n",
      "Epoch 25/50\n",
      "400/400 [==============================] - 134s 334ms/step - loss: 0.4231 - accuracy: 0.8092 - val_loss: 0.4130 - val_accuracy: 0.8084 - lr: 1.5625e-05\n",
      "Epoch 26/50\n",
      "400/400 [==============================] - 136s 341ms/step - loss: 0.4266 - accuracy: 0.8097 - val_loss: 0.4134 - val_accuracy: 0.8078 - lr: 1.5625e-05\n",
      "Epoch 27/50\n",
      "400/400 [==============================] - 121s 304ms/step - loss: 0.4234 - accuracy: 0.8077 - val_loss: 0.4131 - val_accuracy: 0.8081 - lr: 1.0000e-05\n",
      "Epoch 28/50\n",
      "400/400 [==============================] - 123s 309ms/step - loss: 0.4268 - accuracy: 0.8060 - val_loss: 0.4140 - val_accuracy: 0.8084 - lr: 1.0000e-05\n",
      "{0: 'LABEL_0', 1: 'LABEL_1'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification\n",
    "\n",
    "# Charger le tokenizer et le mod√®le automatiquement (transformers choisit RobertaTokenizer / TFRobertaForSequenceClassification)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "                                                        \"finiteautomata/bertweet-base-sentiment-analysis\", \n",
    "                                                        num_labels=2,\n",
    "                                                        ignore_mismatched_sizes=True )\n",
    "\n",
    "for layer in model.layers:\n",
    "    if layer.name != \"classifier\":   # nom de la couche finale\n",
    "        layer.trainable = False\n",
    "\n",
    "# V√©rification\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Tokenisation\n",
    "encodings_train = tokenizer(X_train.to_list(), truncation=True, padding=True, return_tensors=\"tf\")\n",
    "encodings_val = tokenizer(X_val.to_list(), truncation=True, padding=True, return_tensors=\"tf\")\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        {\n",
    "        \"input_ids\": encodings_train[\"input_ids\"], \n",
    "        \"attention_mask\": encodings_train[\"attention_mask\"]\n",
    "        },y_train\n",
    "    )\n",
    "    ).batch(32)\n",
    "        \n",
    "dataset_val = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        {\n",
    "        \"input_ids\": encodings_val[\"input_ids\"], \n",
    "        \"attention_mask\": encodings_val[\"attention_mask\"]\n",
    "        },y_val\n",
    "    )\n",
    "    ).batch(32)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)  # LR plus √©lev√© car seules quelques couches sont entra√Æn√©es\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "rename = '_'.join(\"finiteautomata/bertweet-base-sentiment-analysis\".split('/'))\n",
    "        ## Callbacks\n",
    "model_savepath = f\"./Models/AUTO_{rename}.h5\"\n",
    "checkpoint = ModelCheckpoint(model_savepath, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=0, min_lr=1e-5)\n",
    "callbacks_list = [checkpoint, es, lr_scheduler]\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "# Exemple d‚Äôentra√Ænement\n",
    "history = model.fit(dataset_train, validation_data=dataset_val, epochs=50,callbacks=callbacks_list, verbose=1)\n",
    "\n",
    "print(model.config.id2label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6225eb03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_env_P7_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
