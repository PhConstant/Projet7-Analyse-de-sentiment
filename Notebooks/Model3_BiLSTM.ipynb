{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf76efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\tensorflow_hub\\__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n",
      "Num GPUs Available:  1\n",
      "GPUs disponibles : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Version TF : 2.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import TextVectorization, Embedding, SimpleRNN, Dense, LSTM, Flatten\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim.downloader as gensim_downloader\n",
    "import gensim\n",
    "import multiprocessing\n",
    "from mlflow import MlflowClient\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import TweetTokenizer, WordPunctTokenizer, RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer, LancasterStemmer, SnowballStemmer\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "cwd = Path.cwd()\n",
    "parent = cwd.parent\n",
    "sys.path.append(str(parent))\n",
    "\n",
    "\n",
    "from Source.preprocess_data import *  ## import all functions from preprocess_data.py\n",
    "from Source.postprocess_data import * ## import all functions from postprocess_data.py\n",
    "from Source.utils import *  ## import all functions from utils.py\n",
    "import nltk\n",
    "\n",
    "\n",
    "client = MlflowClient(tracking_uri=\"http://localhost:8080\")\n",
    "\n",
    "mlruns_path = Path(\"../mlruns\").resolve() \n",
    "mlflow_uri = mlruns_path.as_uri()\n",
    "mlflow.set_tracking_uri(mlflow_uri)\n",
    "\n",
    "nw = multiprocessing.cpu_count()\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"TF_KERAS\"]='1'\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPUs disponibles :\", tf.config.list_physical_devices(\"GPU\"))\n",
    "print(\"Version TF :\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85ec2be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 32000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:148: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../Data/raw_data.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:148: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/AI+Engineer/Project+7%C2%A0-+D%C3%A9tectez+les+Bad+Buzz+gr%C3%A2ce+au+Deep+Learning/sentiment140.zip',\n",
    "                header=None,\n",
    "                compression='zip',\n",
    "                encoding='cp1252')\n",
    "\n",
    "df.columns = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "data_size = 0.02\n",
    "sample_df, _ = train_test_split(df, test_size=1-data_size, random_state=42, stratify=df['target'])\n",
    "sample_df = sample_df.reset_index(drop=True)\n",
    "print(f\"Sample size: {sample_df.shape[0]} rows\")\n",
    "data_numrows = sample_df.shape[0]\n",
    "# On ne garde que les colonnes 'target' et 'text'\n",
    "sample_df = sample_df[['target', 'text']]\n",
    "sample_df[\"target\"] = sample_df[\"target\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "sample_df.to_csv('../Data/raw_data.csv', index=False)\n",
    "dataset = mlflow.data.from_pandas(\n",
    "    sample_df,\n",
    "    source=\"../Data/raw_data.csv\",\n",
    "    name=\"dataset_v1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4967e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X_raw = sample_df['text']\n",
    "y = sample_df['target']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_raw, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f35d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "# GloVe Twitter (par exemple 200 dimensions)\n",
    "glove_tw200 = api.load(\"glove-twitter-200\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf513957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (9616, 200)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n"
     ]
    }
   ],
   "source": [
    "## Prétraitement\n",
    "min_count = 2\n",
    "num_words = 30000\n",
    "max_len   = 50\n",
    "# Prétraitement\n",
    "X_sentence_train, tokenizer, sentences_train = preprocess_data_embedding(X_raw=X_train, \n",
    "                                                        stem_lem_func=None,\n",
    "                                                        tokenizer=None, \n",
    "                                                        stop_words=None, \n",
    "                                                        min_count=min_count,\n",
    "                                                        max_len = max_len, \n",
    "                                                        num_words=num_words, \n",
    "                                                        return_sentences=True) \n",
    "X_sentence_val = preprocess_data_embedding(X_raw=X_val, \n",
    "                                                        stem_lem_func=None,\n",
    "                                                        tokenizer=tokenizer, \n",
    "                                                        stop_words=None, \n",
    "                                                        min_count=1, # mincount = 1 car on est sur le jeu de validation\n",
    "                                                        max_len = max_len, \n",
    "                                                        num_words=num_words) \n",
    "\n",
    "\n",
    "model_vectors = glove_tw200\n",
    "latent_dim = glove_tw200.vector_size\n",
    "\n",
    "embedding_matrix, vocab_size = build_embedding_matrix(tokenizer=tokenizer,\n",
    "                                embedding_model=model_vectors, \n",
    "                                latent_dim=latent_dim\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d819ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modèle\n",
    "rnn_size = 128\n",
    "## Entrainement\n",
    "epochs = 50\n",
    "lr = 1e-3\n",
    "max_len = 50\n",
    "## Savepath des poids du modèle\n",
    "\n",
    "def rnn_layer_experiment_bi(rnn_layer_name):\n",
    "     with mlflow.start_run():\n",
    "        mlflow.log_input(dataset)\n",
    "\n",
    "        mlflow.log_params(params={\n",
    "            'num_words':num_words,               \n",
    "            'max_len': max_len,\n",
    "            'min_count': min_count,\n",
    "            'stemmer': 'None', \n",
    "            'latent_dim': latent_dim, \n",
    "            'rnn_size': rnn_size, \n",
    "            'epochs': epochs, \n",
    "            'learning_rate': lr,\n",
    "            'embedding_name':'Glove_twitter_200',\n",
    "            'rnn_layer_name':rnn_layer_name,\n",
    "            \"data_size\": data_size,\n",
    "            \"data_numrows\": data_numrows, \n",
    "        })\n",
    "        model_savepath = \"./Models/\"+rnn_layer_name+\"_model_exp.h5\"\n",
    "        # Modèle\n",
    "\n",
    "        if rnn_layer_name=='LSTM':\n",
    "            model = build_lstm_RNN(vocab_size=vocab_size, \n",
    "                            latent_dim=latent_dim,\n",
    "                            input_length=max_len, \n",
    "                            embedding_matrix=embedding_matrix,\n",
    "                            rnn_size = rnn_size)\n",
    "        elif rnn_layer_name=='Bi-LSTM':\n",
    "            model = build_bilstm_RNN(vocab_size=vocab_size, \n",
    "                            latent_dim=latent_dim,\n",
    "                            input_length=max_len, \n",
    "                            embedding_matrix=embedding_matrix,\n",
    "                            rnn_size = rnn_size)\n",
    "\n",
    "        ## Callbacks\n",
    "        checkpoint = ModelCheckpoint(model_savepath, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min')\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
    "        lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=0, min_lr=1e-5)\n",
    "        callbacks_list = [checkpoint, es, lr_scheduler]\n",
    "        ## Compilation\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "        #Entrainement\n",
    "        with tf.device(\"/GPU:0\"):\n",
    "            history = model.fit(X_sentence_train, y_train, epochs=epochs, batch_size=64, validation_data=(X_sentence_val,y_val), callbacks=callbacks_list, verbose=1)\n",
    "\n",
    "        model.load_weights(model_savepath)\n",
    "\n",
    "                # Prédictions sur le jeu de validation\n",
    "        y_pred_proba = model.predict(X_sentence_val)\n",
    "        y_pred = (y_pred_proba>0.5)\n",
    "\n",
    "\n",
    "        output_dict = postprocess_model_output(y_val, y_pred, y_pred_proba) # voir postprocess_data.py\n",
    "\n",
    "        # Logging des métriques dans MLflow\n",
    "        mlflow.log_metrics(output_dict)\n",
    "        # Matrice de confusion\n",
    "        cm = confusion_matrix(y_val, y_pred, normalize='pred')\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\", ax=ax, )\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.title(\"Confusion Matrix - Validation Set\")\n",
    "        fig.savefig(\"confusion_matrix.png\")\n",
    "        plt.close(fig)\n",
    "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "        #\n",
    "        fig2 = plot_training_history(history,show=False)\n",
    "        fig2.savefig(\"learning_path.png\")\n",
    "        plt.close(fig2)\n",
    "        mlflow.log_artifact(\"learning_path.png\")\n",
    "\n",
    "        # Enregistrement du modèle dans MLflow\n",
    "        mlflow.tensorflow.log_model(model, \"model\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26e583c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 367, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 465, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1635, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1628, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 367, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 465, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1635, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1628, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up MLflow experiment...\n"
     ]
    }
   ],
   "source": [
    "# Création de l'étude Optuna et optimisation\n",
    "print(\"Setting up MLflow experiment...\")\n",
    "mlflow.set_experiment(\"rnn_layer_experiment_pretrained_embedding\")\n",
    "exp_id = mlflow.get_experiment_by_name(\"rnn_layer_experiment_pretrained_embedding\").experiment_id\n",
    "\n",
    "experiment_description = (\n",
    "    \"Comparaison des impact des types de cellules RNN utilisées : SimpleRNN, GRU et LSTM \"\n",
    "    \"\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"Sentiment analysis modelling\",\n",
    "    \"model_type\": \"RNN_types-pretrained-embeddings\",\n",
    "    \"team\": \"Ph. Constant\",\n",
    "    \"project_quarter\": \"Q3-2025\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "for key, value in experiment_tags.items():\n",
    "    client.set_experiment_tag(exp_id, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d25b3f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with Bi-LSTM\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 50, 200)           1923200   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 50, 256)          336896    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 256)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,276,609\n",
      "Trainable params: 353,409\n",
      "Non-trainable params: 1,923,200\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "400/400 [==============================] - 110s 269ms/step - loss: 0.5455 - accuracy: 0.7211 - val_loss: 0.4727 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 104s 261ms/step - loss: 0.4827 - accuracy: 0.7672 - val_loss: 0.4614 - val_accuracy: 0.7809 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 114s 286ms/step - loss: 0.4650 - accuracy: 0.7752 - val_loss: 0.4466 - val_accuracy: 0.7881 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 112s 280ms/step - loss: 0.4514 - accuracy: 0.7854 - val_loss: 0.4456 - val_accuracy: 0.7837 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 109s 273ms/step - loss: 0.4377 - accuracy: 0.7944 - val_loss: 0.4388 - val_accuracy: 0.7939 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 116s 290ms/step - loss: 0.4276 - accuracy: 0.8011 - val_loss: 0.4375 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 120s 299ms/step - loss: 0.4161 - accuracy: 0.8066 - val_loss: 0.4392 - val_accuracy: 0.7969 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 116s 291ms/step - loss: 0.4044 - accuracy: 0.8118 - val_loss: 0.4394 - val_accuracy: 0.7895 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 112s 279ms/step - loss: 0.3836 - accuracy: 0.8227 - val_loss: 0.4361 - val_accuracy: 0.7969 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 116s 291ms/step - loss: 0.3772 - accuracy: 0.8285 - val_loss: 0.4405 - val_accuracy: 0.7966 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 118s 295ms/step - loss: 0.3635 - accuracy: 0.8334 - val_loss: 0.4461 - val_accuracy: 0.7975 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 121s 303ms/step - loss: 0.3518 - accuracy: 0.8394 - val_loss: 0.4558 - val_accuracy: 0.7984 - lr: 2.5000e-04\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 112s 280ms/step - loss: 0.3492 - accuracy: 0.8433 - val_loss: 0.4467 - val_accuracy: 0.7964 - lr: 2.5000e-04\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 114s 284ms/step - loss: 0.3411 - accuracy: 0.8458 - val_loss: 0.4470 - val_accuracy: 0.7958 - lr: 1.2500e-04\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 107s 268ms/step - loss: 0.3397 - accuracy: 0.8453 - val_loss: 0.4515 - val_accuracy: 0.7975 - lr: 1.2500e-04\n",
      "Epoch 16/50\n",
      "400/400 [==============================] - 116s 291ms/step - loss: 0.3325 - accuracy: 0.8518 - val_loss: 0.4556 - val_accuracy: 0.7972 - lr: 6.2500e-05\n",
      "Epoch 17/50\n",
      "400/400 [==============================] - 118s 295ms/step - loss: 0.3265 - accuracy: 0.8539 - val_loss: 0.4579 - val_accuracy: 0.7945 - lr: 6.2500e-05\n",
      "Epoch 18/50\n",
      "400/400 [==============================] - 118s 294ms/step - loss: 0.3291 - accuracy: 0.8530 - val_loss: 0.4584 - val_accuracy: 0.7950 - lr: 3.1250e-05\n",
      "Epoch 19/50\n",
      "400/400 [==============================] - 114s 285ms/step - loss: 0.3261 - accuracy: 0.8540 - val_loss: 0.4573 - val_accuracy: 0.7948 - lr: 3.1250e-05\n",
      "200/200 [==============================] - 13s 63ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/07 00:24:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/07 00:24:28 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpsyvb0c0u\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpsyvb0c0u\\model\\data\\model\\assets\n",
      "2025/10/07 00:24:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "400/400 [==============================] - 17s 32ms/step - loss: 0.5166 - accuracy: 0.7445 - val_loss: 0.4698 - val_accuracy: 0.7777 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "400/400 [==============================] - 12s 29ms/step - loss: 0.4533 - accuracy: 0.7861 - val_loss: 0.4494 - val_accuracy: 0.7856 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "400/400 [==============================] - 13s 34ms/step - loss: 0.4252 - accuracy: 0.8027 - val_loss: 0.4397 - val_accuracy: 0.7908 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: 0.3986 - accuracy: 0.8181 - val_loss: 0.4361 - val_accuracy: 0.7909 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "400/400 [==============================] - 14s 34ms/step - loss: 0.3729 - accuracy: 0.8347 - val_loss: 0.4351 - val_accuracy: 0.7914 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "400/400 [==============================] - 14s 34ms/step - loss: 0.3417 - accuracy: 0.8527 - val_loss: 0.4385 - val_accuracy: 0.7923 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: 0.3101 - accuracy: 0.8722 - val_loss: 0.4503 - val_accuracy: 0.7900 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: 0.2593 - accuracy: 0.9013 - val_loss: 0.4660 - val_accuracy: 0.7878 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 0.2321 - accuracy: 0.9150 - val_loss: 0.4898 - val_accuracy: 0.7831 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 0.1991 - accuracy: 0.9344 - val_loss: 0.5135 - val_accuracy: 0.7811 - lr: 2.5000e-04\n",
      "Epoch 11/50\n",
      "400/400 [==============================] - 12s 31ms/step - loss: 0.1842 - accuracy: 0.9396 - val_loss: 0.5223 - val_accuracy: 0.7795 - lr: 2.5000e-04\n",
      "Epoch 12/50\n",
      "400/400 [==============================] - 13s 31ms/step - loss: 0.1657 - accuracy: 0.9495 - val_loss: 0.5527 - val_accuracy: 0.7758 - lr: 1.2500e-04\n",
      "Epoch 13/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: 0.1579 - accuracy: 0.9531 - val_loss: 0.5675 - val_accuracy: 0.7763 - lr: 1.2500e-04\n",
      "Epoch 14/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: 0.1490 - accuracy: 0.9566 - val_loss: 0.5770 - val_accuracy: 0.7752 - lr: 6.2500e-05\n",
      "Epoch 15/50\n",
      "400/400 [==============================] - 13s 33ms/step - loss: 0.1448 - accuracy: 0.9585 - val_loss: 0.5839 - val_accuracy: 0.7755 - lr: 6.2500e-05\n",
      "200/200 [==============================] - 2s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/07 00:28:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/07 00:28:09 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpvxcfotlg\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpvxcfotlg\\model\\data\\model\\assets\n",
      "2025/10/07 00:28:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Running test with Bi-LSTM\")\n",
    "rnn_layer_experiment_bi(\"Bi-LSTM\")\n",
    "rnn_layer_experiment_bi(\"LSTM\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4310e0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_env_P7_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
