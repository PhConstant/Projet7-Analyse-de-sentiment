{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43c17c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\tensorflow_hub\\__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n",
      "Num GPUs Available:  1\n",
      "GPUs disponibles : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Version TF : 2.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import TextVectorization, Embedding, SimpleRNN, Dense, LSTM, Flatten\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim.downloader as gensim_downloader\n",
    "import gensim\n",
    "import multiprocessing\n",
    "from mlflow import MlflowClient\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import TweetTokenizer, WordPunctTokenizer, RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer, LancasterStemmer, SnowballStemmer\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "cwd = Path.cwd()\n",
    "parent = cwd.parent\n",
    "sys.path.append(str(parent))\n",
    "\n",
    "\n",
    "from Source.preprocess_data import *  ## import all functions from preprocess_data.py\n",
    "from Source.postprocess_data import * ## import all functions from postprocess_data.py\n",
    "from Source.utils import *  ## import all functions from utils.py\n",
    "import nltk\n",
    "\n",
    "\n",
    "client = MlflowClient(tracking_uri=\"http://localhost:8080\")\n",
    "\n",
    "mlruns_path = Path(\"../mlruns\").resolve() \n",
    "mlflow_uri = mlruns_path.as_uri()\n",
    "mlflow.set_tracking_uri(mlflow_uri)\n",
    "\n",
    "nw = multiprocessing.cpu_count()\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"TF_KERAS\"]='1'\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPUs disponibles :\", tf.config.list_physical_devices(\"GPU\"))\n",
    "print(\"Version TF :\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "969e2c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 32000 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:148: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for '../Data/raw_data.csv'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\data\\dataset_source_registry.py:148: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/AI+Engineer/Project+7%C2%A0-+D%C3%A9tectez+les+Bad+Buzz+gr%C3%A2ce+au+Deep+Learning/sentiment140.zip',\n",
    "                header=None,\n",
    "                compression='zip',\n",
    "                encoding='cp1252')\n",
    "\n",
    "df.columns = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "data_size = 0.02\n",
    "sample_df, _ = train_test_split(df, test_size=1-data_size, random_state=42, stratify=df['target'])\n",
    "sample_df = sample_df.reset_index(drop=True)\n",
    "print(f\"Sample size: {sample_df.shape[0]} rows\")\n",
    "data_numrows = sample_df.shape[0]\n",
    "# On ne garde que les colonnes 'target' et 'text'\n",
    "sample_df = sample_df[['target', 'text']]\n",
    "sample_df[\"target\"] = sample_df[\"target\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "sample_df.to_csv('../Data/raw_data.csv', index=False)\n",
    "dataset = mlflow.data.from_pandas(\n",
    "    sample_df,\n",
    "    source=\"../Data/raw_data.csv\",\n",
    "    name=\"dataset_v1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2583e99",
   "metadata": {},
   "source": [
    "# Séparation train/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8a5c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X_raw = sample_df['text']\n",
    "y = sample_df['target']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_raw, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5697acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f95011c",
   "metadata": {},
   "source": [
    "# Préparation de l'experience de base (baseline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fbc2cd",
   "metadata": {},
   "source": [
    "## Pré-traitement des dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "478f1fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 20000\n",
    "max_len = 10\n",
    "min_count = 3\n",
    "\n",
    "X_sentence_train, tokenizer, sentences_train = preprocess_data_embedding(X_raw=X_train, \n",
    "                                                        stem_lem_func=PorterStemmer().stem,\n",
    "                                                        tokenizer=None, \n",
    "                                                        stop_words=stopwords.words('english'), \n",
    "                                                        min_count=min_count,\n",
    "                                                        max_len = max_len, \n",
    "                                                        num_words=num_words, \n",
    "                                                        return_sentences=True) \n",
    "X_sentence_val = preprocess_data_embedding(X_raw=X_val, \n",
    "                                                        stem_lem_func=PorterStemmer().stem,\n",
    "                                                        tokenizer=tokenizer, \n",
    "                                                        stop_words=stopwords.words('english'), \n",
    "                                                        min_count=1, # mincount = 1 car on est sur le jeu de validation\n",
    "                                                        max_len = max_len, \n",
    "                                                        num_words=num_words) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef45eb84",
   "metadata": {},
   "source": [
    "# Création d'un embedding de base custom pour notre modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12bc38bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build & train Word2Vec model ...\n",
      "Vocabulary size: 5491\n",
      "Word2Vec trained\n",
      "Coverage: 99.98%\n",
      "Mean norm: 6.3330092\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "latent_dim = 50\n",
    "print(\"Build & train Word2Vec model ...\")\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=sentences_train, \n",
    "    vector_size=latent_dim,  # dimension de l’espace latent\n",
    "    window=5,         # taille du contexte\n",
    "    min_count=min_count,      # ignorer les mots trop rares\n",
    "    workers=4,        # parallélisme CPU\n",
    "    sg=0,              # 1 = skip-gram, 0 = CBOW\n",
    "    epochs=100\n",
    ")\n",
    "\n",
    "\n",
    "model_vectors = w2v_model.wv\n",
    "w2v_words = model_vectors.index_to_key\n",
    "print(\"Vocabulary size: %i\" % len(w2v_words))\n",
    "print(\"Word2Vec trained\")\n",
    "\n",
    "found = sum(1 for w in tokenizer.word_index if w in w2v_model.wv)\n",
    "coverage = found / len(tokenizer.word_index)\n",
    "print(f\"Coverage: {coverage*100:.2f}%\")\n",
    "\n",
    "vectors = np.array([w2v_model.wv[w] for w in tokenizer.word_index if w in w2v_model.wv])\n",
    "print(\"Mean norm:\", np.mean(np.linalg.norm(vectors, axis=1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba88b04d",
   "metadata": {},
   "source": [
    "## Création de la matrice d'embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "664fbb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (5493, 50)\n",
      "Words found in pretrained embeddings: 5491/5493 (99.96%)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix, vocab_size = build_embedding_matrix(tokenizer=tokenizer,\n",
    "                                          embedding_model=model_vectors, \n",
    "                                          latent_dim=latent_dim\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0441bc8",
   "metadata": {},
   "source": [
    "## Création du modèle simple avec RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec0b1894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 10, 50)            274650    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 10, 64)            7360      \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 64)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 282,075\n",
      "Trainable params: 7,425\n",
      "Non-trainable params: 274,650\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model =  build_base_RNN(vocab_size=vocab_size, \n",
    "                        latent_dim=latent_dim,\n",
    "                        input_length=max_len, \n",
    "                        embedding_matrix=embedding_matrix,\n",
    "                        rnn_size = 64)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326f6b4a",
   "metadata": {},
   "source": [
    "## Callbacks pour l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c34df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./Models/baselineRNN.h5\", monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=0, min_lr=1e-5)\n",
    "optimizer = Adam(learning_rate=1e-3)\n",
    "\n",
    "callbacks_list = [checkpoint, es, lr_scheduler]\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716708dd",
   "metadata": {},
   "source": [
    "## Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a2eabb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/GPU:0\"):\n",
    "    history = model.fit(X_sentence_train, y_train, epochs=50, batch_size=64, validation_data=(X_sentence_val,y_val), callbacks=callbacks_list, verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d23f7",
   "metadata": {},
   "source": [
    "## Post-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29e8dacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.70421875,\n",
       " 'F1_negatif': 0.7044496487119438,\n",
       " 'F1_positif': 0.7039874902267397,\n",
       " 'Recall_negatif': 0.705,\n",
       " 'Recall_positif': 0.7034375,\n",
       " 'Precision_negatif': 0.7039001560062402,\n",
       " 'Precision_positif': 0.7045383411580595,\n",
       " 'ROC_AUC': 0.777373828125}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = model.predict(X_sentence_val)\n",
    "y_pred = (y_pred_proba>0.5)\n",
    "\n",
    "\n",
    "output_dict = postprocess_model_output(y_val, y_pred, y_pred_proba) # voir postprocess_data.py\n",
    "\n",
    "output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d820a8",
   "metadata": {},
   "source": [
    "## Liste des hyper-paramètres à optimiser \n",
    "\n",
    "\n",
    "- Prétraitement : \n",
    "    - Stemming ou Lemmatisation\n",
    "    - Taille du vocabulaire (num_words)\n",
    "    - Nombre minimum d'occurences (min_count)\n",
    "\n",
    "- Embedding : \n",
    "    - Word2Vec/FastText/Glove (préentrainés)\n",
    "    - Word2Vec/FastText (customisés)\n",
    "    - Dimension latente de l'embedding\n",
    "- Modèle : \n",
    "    - Couche SimpleRNN ou LSTM\n",
    "    - Dimension de la couche d'entrainement\n",
    "    - Fine-tuning ou non des embeddings ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27a1bea",
   "metadata": {},
   "source": [
    "# Experimentations sur les modèles de RNN classiques "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90a8bd7",
   "metadata": {},
   "source": [
    "## Préparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "729e9ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WordNetLemmatizer', 'PorterStemmer', 'LancasterStemmer', 'SnowballStemmer']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Stemmer_dict = {'WordNetLemmatizer': WordNetLemmatizer().lemmatize, \n",
    "                'PorterStemmer': PorterStemmer().stem, \n",
    "                'LancasterStemmer':LancasterStemmer().stem, \n",
    "                'SnowballStemmer' : SnowballStemmer(\"english\").stem\n",
    "}\n",
    "\n",
    "list(Stemmer_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8c21a8",
   "metadata": {},
   "source": [
    "## Core fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dbbba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction à optimiser pour optuna\n",
    "\n",
    "def embedding_eva_pre(trial):\n",
    "    # Hyperparamètres\n",
    "    ## Prétraitement\n",
    "    min_count = trial.suggest_int('min_count',1,10)\n",
    "    num_words = trial.suggest_int('num_words',5000,50000)\n",
    "    max_len   = trial.suggest_int('max_len',2,30)\n",
    "    stemmer   = trial.suggest_categorical('stemmer',list(Stemmer_dict.keys()))\n",
    "    ## Embedding\n",
    "    latent_dim = 50\n",
    "    ## Modèle\n",
    "    rnn_size = 64\n",
    "    ## Entrainement\n",
    "    epochs = 50\n",
    "    lr = 1e-3\n",
    "    ## Savepath des poids du modèle\n",
    "    model_savepath = \"./Models/baselineRNN_pre.h5\"\n",
    "\n",
    "\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.log_input(dataset)\n",
    "\n",
    "        mlflow.log_params(params={\n",
    "            'num_words':num_words,               \n",
    "            'max_len': max_len,\n",
    "            'min_count': min_count,\n",
    "            'stemmer': stemmer, \n",
    "            'latent_dim': latent_dim, \n",
    "            'rnn_size': rnn_size, \n",
    "            'epochs': epochs, \n",
    "            'learning_rate': lr,\n",
    "            \"data_size\": data_size,\n",
    "            \"data_numrows\": data_numrows, \n",
    "        })\n",
    "\n",
    "        # Prétraitement\n",
    "        X_sentence_train, tokenizer, sentences_train = preprocess_data_embedding(X_raw=X_train, \n",
    "                                                        stem_lem_func=Stemmer_dict[stemmer],\n",
    "                                                        tokenizer=None, \n",
    "                                                        stop_words=stopwords.words('english'), \n",
    "                                                        min_count=min_count,\n",
    "                                                        max_len = max_len, \n",
    "                                                        num_words=num_words, \n",
    "                                                        return_sentences=True) \n",
    "        X_sentence_val = preprocess_data_embedding(X_raw=X_val, \n",
    "                                                        stem_lem_func=PorterStemmer().stem,\n",
    "                                                        tokenizer=tokenizer, \n",
    "                                                        stop_words=stopwords.words('english'), \n",
    "                                                        min_count=1, # mincount = 1 car on est sur le jeu de validation\n",
    "                                                        max_len = max_len, \n",
    "                                                        num_words=num_words) \n",
    "        # Embedding(custom)\n",
    "        \n",
    "        w2v_model = Word2Vec(\n",
    "            sentences=sentences_train, \n",
    "            vector_size=latent_dim,  # dimension de l’espace latent\n",
    "            window=5,         # taille du contexte\n",
    "            min_count=min_count,      # ignorer les mots trop rares\n",
    "            workers=4,        # parallélisme CPU\n",
    "            sg=0,              # 1 = skip-gram, 0 = CBOW\n",
    "            epochs=50\n",
    "            )\n",
    "\n",
    "\n",
    "        model_vectors = w2v_model.wv\n",
    "        w2v_words = model_vectors.index_to_key\n",
    "\n",
    "        embedding_matrix, vocab_size = build_embedding_matrix(tokenizer=tokenizer,\n",
    "                                          embedding_model=model_vectors, \n",
    "                                          latent_dim=latent_dim\n",
    "                                          )\n",
    "\n",
    "        \n",
    "        # Modèle\n",
    "        model =  build_base_RNN(vocab_size=vocab_size, \n",
    "                        latent_dim=latent_dim,\n",
    "                        input_length=max_len, \n",
    "                        embedding_matrix=embedding_matrix,\n",
    "                        rnn_size = rnn_size)\n",
    "        ## Callbacks\n",
    "        checkpoint = ModelCheckpoint(model_savepath, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min')\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
    "        lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=0, min_lr=1e-5)\n",
    "        callbacks_list = [checkpoint, es, lr_scheduler]\n",
    "        ## Compilation\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "        #Entrainement\n",
    "        with tf.device(\"/GPU:0\"):\n",
    "            history = model.fit(X_sentence_train, y_train, epochs=epochs, batch_size=64, validation_data=(X_sentence_val,y_val), callbacks=callbacks_list, verbose=0)\n",
    "\n",
    "        model.load_weights(model_savepath)\n",
    "\n",
    "        # Prédictions sur le jeu de validation\n",
    "        y_pred_proba = model.predict(X_sentence_val)\n",
    "        y_pred = (y_pred_proba>0.5)\n",
    "\n",
    "\n",
    "        output_dict = postprocess_model_output(y_val, y_pred, y_pred_proba) # voir postprocess_data.py\n",
    "\n",
    "        # Logging des métriques dans MLflow\n",
    "        mlflow.log_metrics(output_dict)\n",
    "        # Matrice de confusion\n",
    "        cm = confusion_matrix(y_val, y_pred, normalize='pred')\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\", ax=ax, )\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.title(\"Confusion Matrix - Validation Set\")\n",
    "        fig.savefig(\"confusion_matrix.png\")\n",
    "        plt.close(fig)\n",
    "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "        #\n",
    "        fig2 = plot_training_history(history,show=False)\n",
    "        fig2.savefig(\"learning_path.png\")\n",
    "        plt.close(fig2)\n",
    "        mlflow.log_artifact(\"learning_path.png\")\n",
    "\n",
    "        # Enregistrement du modèle dans MLflow\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        acc = output_dict[\"Accuracy\"]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded01f83",
   "metadata": {},
   "source": [
    "## Définition de l'experiment MLFlow/Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cad89439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter optimization with Optuna...\n",
      "Setting up MLflow experiment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 367, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 465, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1635, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1628, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 367, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 465, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1635, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1628, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n"
     ]
    }
   ],
   "source": [
    "# Création de l'étude Optuna et optimisation\n",
    "print(\"Starting hyperparameter optimization with Optuna...\")\n",
    "print(\"Setting up MLflow experiment...\")\n",
    "mlflow.set_experiment(\"optuna_word_embedding_experiment_preprocessin\")\n",
    "exp_id = mlflow.get_experiment_by_name(\"optuna_word_embedding_experiment_preprocessin\").experiment_id\n",
    "\n",
    "experiment_description = (\n",
    "    \"Cette experience contient les différents tests pour le modèle RNN simple. \"\n",
    "    \"Ici on évalue simplement l'impact des différents prétraitements sur un modèle avec simpleRNN\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"Sentiment analysis modelling\",\n",
    "    \"model_type\": \"simple-RNN-preprocessing\",\n",
    "    \"team\": \"Ph. Constant\",\n",
    "    \"project_quarter\": \"Q3-2025\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "for key, value in experiment_tags.items():\n",
    "    client.set_experiment_tag(exp_id, key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afb2165",
   "metadata": {},
   "source": [
    "## Lancement de l'optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4247717f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 13:55:58 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp98wsciu1\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 13:55:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 13:55:58,752] Trial 27 finished with value: 0.709375 and parameters: {'min_count': 4, 'num_words': 36201, 'max_len': 20, 'stemmer': 'PorterStemmer'}. Best is trial 15 with value: 0.7209375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (3622, 50)\n",
      "Words found in pretrained embeddings: 3620/3622 (99.94%)\n",
      "200/200 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 13:58:32 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://881c32db-fdf1-4e2a-87cb-24dd87795d63/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://881c32db-fdf1-4e2a-87cb-24dd87795d63/assets\n",
      "2025/10/06 13:58:43 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp3pwqdvqx\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 13:58:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 13:58:43,259] Trial 28 finished with value: 0.71171875 and parameters: {'min_count': 5, 'num_words': 24064, 'max_len': 26, 'stemmer': 'PorterStemmer'}. Best is trial 15 with value: 0.7209375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (5493, 50)\n",
      "Words found in pretrained embeddings: 5491/5493 (99.96%)\n",
      "200/200 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:01:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://e7fd3748-b2c7-4407-a356-0fcaf406b1c5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://e7fd3748-b2c7-4407-a356-0fcaf406b1c5/assets\n",
      "2025/10/06 14:01:20 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpaxzlpnny\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:01:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:01:20,342] Trial 29 finished with value: 0.7221875 and parameters: {'min_count': 3, 'num_words': 18037, 'max_len': 17, 'stemmer': 'PorterStemmer'}. Best is trial 29 with value: 0.7221875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (3144, 50)\n",
      "Words found in pretrained embeddings: 3142/3144 (99.94%)\n",
      "200/200 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:03:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://212140ed-88a9-428e-83f8-d4dc6e775936/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://212140ed-88a9-428e-83f8-d4dc6e775936/assets\n",
      "2025/10/06 14:03:58 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmptxig87gn\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:03:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:03:58,701] Trial 30 finished with value: 0.70984375 and parameters: {'min_count': 6, 'num_words': 10649, 'max_len': 16, 'stemmer': 'PorterStemmer'}. Best is trial 29 with value: 0.7221875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (5493, 50)\n",
      "Words found in pretrained embeddings: 5491/5493 (99.96%)\n",
      "200/200 [==============================] - 2s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:06:33 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://5a953a11-b0a7-4878-9f89-fa536c59aece/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://5a953a11-b0a7-4878-9f89-fa536c59aece/assets\n",
      "2025/10/06 14:06:42 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpbb2rdtz7\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:06:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:06:43,178] Trial 31 finished with value: 0.711875 and parameters: {'min_count': 3, 'num_words': 18164, 'max_len': 19, 'stemmer': 'PorterStemmer'}. Best is trial 29 with value: 0.7221875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 50)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:09:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://882fe8da-6e30-4b53-bccb-d745ae60b6ea/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://882fe8da-6e30-4b53-bccb-d745ae60b6ea/assets\n",
      "2025/10/06 14:09:36 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp7g674pd7\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:09:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:09:36,677] Trial 32 finished with value: 0.71703125 and parameters: {'min_count': 2, 'num_words': 23764, 'max_len': 18, 'stemmer': 'PorterStemmer'}. Best is trial 29 with value: 0.7221875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (4358, 50)\n",
      "Words found in pretrained embeddings: 4356/4358 (99.95%)\n",
      "200/200 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:11:47 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://b0a5e8bf-5599-417e-b8fc-fb7c21e19314/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://b0a5e8bf-5599-417e-b8fc-fb7c21e19314/assets\n",
      "2025/10/06 14:11:57 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpzhglhuzl\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:11:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:11:57,584] Trial 33 finished with value: 0.7153125 and parameters: {'min_count': 4, 'num_words': 14106, 'max_len': 14, 'stemmer': 'PorterStemmer'}. Best is trial 29 with value: 0.7221875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (5493, 50)\n",
      "Words found in pretrained embeddings: 5491/5493 (99.96%)\n",
      "200/200 [==============================] - 2s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:15:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://cbc9603f-d7d3-44e3-b530-9277007596e8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://cbc9603f-d7d3-44e3-b530-9277007596e8/assets\n",
      "2025/10/06 14:15:19 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpu03zo1c7\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:15:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:15:19,319] Trial 34 finished with value: 0.70921875 and parameters: {'min_count': 3, 'num_words': 28171, 'max_len': 27, 'stemmer': 'PorterStemmer'}. Best is trial 29 with value: 0.7221875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (8730, 50)\n",
      "Words found in pretrained embeddings: 8728/8730 (99.98%)\n",
      "200/200 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:16:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f8c16d72-9d5a-4594-acf1-f8f957ec4fc4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f8c16d72-9d5a-4594-acf1-f8f957ec4fc4/assets\n",
      "2025/10/06 14:16:52 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp501n1cjc\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:16:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:16:52,525] Trial 35 finished with value: 0.68296875 and parameters: {'min_count': 2, 'num_words': 24679, 'max_len': 10, 'stemmer': 'WordNetLemmatizer'}. Best is trial 29 with value: 0.7221875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (4358, 50)\n",
      "Words found in pretrained embeddings: 4356/4358 (99.95%)\n",
      "200/200 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:19:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a62e86cc-d9eb-4017-a775-06d2bd22effa/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a62e86cc-d9eb-4017-a775-06d2bd22effa/assets\n",
      "2025/10/06 14:19:58 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp0psc9r70\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:19:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:19:58,312] Trial 36 finished with value: 0.7134375 and parameters: {'min_count': 4, 'num_words': 19325, 'max_len': 21, 'stemmer': 'PorterStemmer'}. Best is trial 29 with value: 0.7221875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (5493, 50)\n",
      "Words found in pretrained embeddings: 5491/5493 (99.96%)\n",
      "200/200 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:22:42 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://4283e85c-0e42-4174-b3e0-fc891ee04837/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://4283e85c-0e42-4174-b3e0-fc891ee04837/assets\n",
      "2025/10/06 14:22:50 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp_lhbm3e8\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:22:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:22:51,095] Trial 37 finished with value: 0.71125 and parameters: {'min_count': 3, 'num_words': 15872, 'max_len': 23, 'stemmer': 'PorterStemmer'}. Best is trial 29 with value: 0.7221875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (4031, 50)\n",
      "Words found in pretrained embeddings: 4029/4031 (99.95%)\n",
      "200/200 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:24:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://ace99a52-7b7a-4bc3-81d5-870f558b991a/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://ace99a52-7b7a-4bc3-81d5-870f558b991a/assets\n",
      "2025/10/06 14:25:00 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp0ukh2353\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:25:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:25:01,076] Trial 38 finished with value: 0.68375 and parameters: {'min_count': 4, 'num_words': 22354, 'max_len': 15, 'stemmer': 'LancasterStemmer'}. Best is trial 29 with value: 0.7221875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (3902, 50)\n",
      "Words found in pretrained embeddings: 3900/3902 (99.95%)\n",
      "200/200 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:26:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://dd7f119f-ca03-4a51-b1c2-7bec45f80a3f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://dd7f119f-ca03-4a51-b1c2-7bec45f80a3f/assets\n",
      "2025/10/06 14:26:51 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp4u_jr1d7\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:26:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:26:51,832] Trial 39 finished with value: 0.6765625 and parameters: {'min_count': 5, 'num_words': 26181, 'max_len': 11, 'stemmer': 'WordNetLemmatizer'}. Best is trial 29 with value: 0.7221875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (2151, 50)\n",
      "Words found in pretrained embeddings: 2149/2151 (99.91%)\n",
      "200/200 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:30:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://630f4dc7-eed9-4df2-9624-0d36d782d8f9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://630f4dc7-eed9-4df2-9624-0d36d782d8f9/assets\n",
      "2025/10/06 14:30:16 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpg5nj3evu\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:30:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:30:16,644] Trial 40 finished with value: 0.7175 and parameters: {'min_count': 10, 'num_words': 49847, 'max_len': 30, 'stemmer': 'PorterStemmer'}. Best is trial 29 with value: 0.7221875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 50)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 2s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:33:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://36eb9868-ba3b-4465-849f-7504b6370a2f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://36eb9868-ba3b-4465-849f-7504b6370a2f/assets\n",
      "2025/10/06 14:33:17 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp1atvj1ba\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:33:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:33:17,841] Trial 41 finished with value: 0.71203125 and parameters: {'min_count': 2, 'num_words': 26232, 'max_len': 22, 'stemmer': 'PorterStemmer'}. Best is trial 29 with value: 0.7221875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 50)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:34:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://baa65a37-efce-4d3d-b6d3-8a46ea44d01b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://baa65a37-efce-4d3d-b6d3-8a46ea44d01b/assets\n",
      "2025/10/06 14:34:46 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpx0_260_u\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:34:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:34:46,256] Trial 42 finished with value: 0.70265625 and parameters: {'min_count': 2, 'num_words': 29910, 'max_len': 8, 'stemmer': 'PorterStemmer'}. Best is trial 29 with value: 0.7221875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (18184, 50)\n",
      "Words found in pretrained embeddings: 18182/18184 (99.99%)\n",
      "200/200 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:37:32 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://074a1546-a4b5-43df-82e1-0c6f47adbdac/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://074a1546-a4b5-43df-82e1-0c6f47adbdac/assets\n",
      "2025/10/06 14:37:42 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpv2grou_7\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:37:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:37:42,289] Trial 43 finished with value: 0.708125 and parameters: {'min_count': 1, 'num_words': 17395, 'max_len': 21, 'stemmer': 'PorterStemmer'}. Best is trial 29 with value: 0.7221875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (4959, 50)\n",
      "Words found in pretrained embeddings: 4957/4959 (99.96%)\n",
      "200/200 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:39:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f0cd49dc-1862-49d0-b4df-affa2e1cbf4b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f0cd49dc-1862-49d0-b4df-affa2e1cbf4b/assets\n",
      "2025/10/06 14:40:04 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp30o_fpaz\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:40:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:40:04,476] Trial 44 finished with value: 0.69078125 and parameters: {'min_count': 3, 'num_words': 35471, 'max_len': 18, 'stemmer': 'LancasterStemmer'}. Best is trial 29 with value: 0.7221875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (18184, 50)\n",
      "Words found in pretrained embeddings: 18182/18184 (99.99%)\n",
      "200/200 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:42:55 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://22170f28-5024-41a2-9dee-55bab6a16193/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://22170f28-5024-41a2-9dee-55bab6a16193/assets\n",
      "2025/10/06 14:43:03 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpr6s4puho\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:43:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:43:04,125] Trial 45 finished with value: 0.72671875 and parameters: {'min_count': 1, 'num_words': 27395, 'max_len': 24, 'stemmer': 'PorterStemmer'}. Best is trial 45 with value: 0.72671875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (21117, 50)\n",
      "Words found in pretrained embeddings: 21115/21117 (99.99%)\n",
      "200/200 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:45:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://990c7e45-4d02-41aa-ad83-af11bd7a8213/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://990c7e45-4d02-41aa-ad83-af11bd7a8213/assets\n",
      "2025/10/06 14:46:00 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmptfwd9bla\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:46:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:46:00,845] Trial 46 finished with value: 0.6853125 and parameters: {'min_count': 1, 'num_words': 22585, 'max_len': 24, 'stemmer': 'WordNetLemmatizer'}. Best is trial 45 with value: 0.72671875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (18184, 50)\n",
      "Words found in pretrained embeddings: 18182/18184 (99.99%)\n",
      "200/200 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:48:57 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://021f5bec-54eb-4068-a6b8-f671335eae04/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://021f5bec-54eb-4068-a6b8-f671335eae04/assets\n",
      "2025/10/06 14:49:06 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmprn1380p2\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:49:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:49:06,432] Trial 47 finished with value: 0.71828125 and parameters: {'min_count': 1, 'num_words': 25376, 'max_len': 26, 'stemmer': 'PorterStemmer'}. Best is trial 45 with value: 0.72671875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (2817, 50)\n",
      "Words found in pretrained embeddings: 2815/2817 (99.93%)\n",
      "200/200 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:52:40 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://3eb3c6f5-b31a-49b0-a082-b18efbce855b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://3eb3c6f5-b31a-49b0-a082-b18efbce855b/assets\n",
      "2025/10/06 14:52:49 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp_3_7ce_x\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:52:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:52:50,153] Trial 48 finished with value: 0.718125 and parameters: {'min_count': 7, 'num_words': 9070, 'max_len': 29, 'stemmer': 'PorterStemmer'}. Best is trial 45 with value: 0.72671875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (15701, 50)\n",
      "Words found in pretrained embeddings: 15699/15701 (99.99%)\n",
      "200/200 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 14:56:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://91ba722e-3619-470f-a02d-9334bb029090/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://91ba722e-3619-470f-a02d-9334bb029090/assets\n",
      "2025/10/06 14:56:14 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpa37964to\\model\\model.pkl, flavor: sklearn). Fall back to return ['scikit-learn==1.7.2', 'cloudpickle==3.1.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2025/10/06 14:56:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 14:56:15,056] Trial 49 finished with value: 0.68671875 and parameters: {'min_count': 1, 'num_words': 20160, 'max_len': 27, 'stemmer': 'LancasterStemmer'}. Best is trial 45 with value: 0.72671875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization completed.\n"
     ]
    }
   ],
   "source": [
    "# Lancement de l'optimisation avec Optuna\n",
    "print(\"Starting optimization trials...\")\n",
    "with mlflow.start_run(run_name=\"optuna_word_embedding_experiment_preprocessin\"):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(embedding_eva_pre, n_trials=50)\n",
    "\n",
    "    mlflow.log_params(study.best_params)\n",
    "    mlflow.log_metric(\"best_accuracy\", study.best_value)\n",
    "\n",
    "print(\"Optimization completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e156241",
   "metadata": {},
   "source": [
    "## Extraction meilleur modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea7a2618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 367, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 465, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1635, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1628, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run ID: ec4aa4d9ebd448c192219024711a0f0e with metrics:\n",
      "Accuracy: 0.72671875\n",
      "F1_negatif: 0.7226011102299762\n",
      "F1_positif: 0.730715935334873\n",
      "Precision_negatif: 0.7336553945249598\n",
      "Precision_positif: 0.7201820940819423\n",
      "Recall_negatif: 0.711875\n",
      "Recall_positif: 0.7415625\n",
      "ROC_AUC: 0.8004910644531249\n",
      "Best run parameters:\n",
      "data_numrows: 32000\n",
      "data_size: 0.02\n",
      "epochs: 50\n",
      "latent_dim: 50\n",
      "learning_rate: 0.001\n",
      "max_len: 24\n",
      "min_count: 1\n",
      "num_words: 27395\n",
      "rnn_size: 64\n",
      "stemmer: PorterStemmer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'simple_rnn_best_pre' already exists. Creating a new version of this model...\n",
      "2025/10/06 14:56:19 WARNING mlflow.tracking._model_registry.fluent: Run with id ec4aa4d9ebd448c192219024711a0f0e has no artifacts at artifact path 'model', registering model based on models:/m-4710df3fd2de4a6e83444f1f96a00742 instead\n",
      "Created version '3' of model 'simple_rnn_best_pre'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting tag data_numrows = 32000 in registered model\n",
      "Setting tag data_size = 0.02 in registered model\n",
      "Setting tag epochs = 50 in registered model\n",
      "Setting tag latent_dim = 50 in registered model\n",
      "Setting tag learning_rate = 0.001 in registered model\n",
      "Setting tag max_len = 24 in registered model\n",
      "Setting tag min_count = 1 in registered model\n",
      "Setting tag num_words = 27395 in registered model\n",
      "Setting tag rnn_size = 64 in registered model\n",
      "Setting tag stemmer = PorterStemmer in registered model\n"
     ]
    }
   ],
   "source": [
    "client = MlflowClient(tracking_uri=\"http://localhost:8080\")\n",
    "experiment_id = mlflow.get_experiment_by_name(\"optuna_word_embedding_experiment_preprocessin\").experiment_id\n",
    "runs = client.search_runs(experiment_id)\n",
    "\n",
    "# Métrique pour sélectionner le meilleur modèle\n",
    "metric_to_optimize = \"Accuracy\" # liste des métriques enregistrées dans postprocess_data.py ou sur l'UI MLflow\n",
    "best_run = max(runs, key=lambda run: run.data.metrics.get(metric_to_optimize, float('-inf')))\n",
    "print(f\"Best run ID: {best_run.info.run_id} with metrics:\")\n",
    "for key, value in best_run.data.metrics.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(f\"Best run parameters:\")\n",
    "for key, value in best_run.data.params.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Enregistrement du meilleur modèle\n",
    "best_model_uri = f\"runs:/{best_run.info.run_id}/model\"\n",
    "registered_model_name = \"simple_rnn_best_pre\"\n",
    "registered_model = mlflow.register_model(best_model_uri, registered_model_name)\n",
    "# Enregistrement des paramètres sous forme de tags dans le modèle enregistré\n",
    "for key, value in best_run.data.params.items():\n",
    "    print(f\"Setting tag {key} = {value} in registered model\")\n",
    "    client.set_model_version_tag(\n",
    "        name=registered_model_name,\n",
    "        version=str(registered_model.version),\n",
    "        key=str(key),\n",
    "        value=str(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0a882a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d4aeae5",
   "metadata": {},
   "source": [
    "# Experimentation sur les embeddings (custom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4b0f02",
   "metadata": {},
   "source": [
    "## Préparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58932e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText, Word2Vec\n",
    "\n",
    "embedding_dict = {'Word2Vec':Word2Vec, \n",
    "                  'FastText':FastText}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca2b238",
   "metadata": {},
   "source": [
    "## Core fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86f78a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction à optimiser pour optuna\n",
    "\n",
    "## Prétraitement\n",
    "min_count = 2\n",
    "num_words = 30000\n",
    "max_len   = 30\n",
    "stemmer   = 'PorterStemmer'\n",
    "# Prétraitement\n",
    "X_sentence_train, tokenizer, sentences_train = preprocess_data_embedding(X_raw=X_train, \n",
    "                                                        stem_lem_func=PorterStemmer().stem,\n",
    "                                                        tokenizer=None, \n",
    "                                                        stop_words=stopwords.words('english'), \n",
    "                                                        min_count=min_count,\n",
    "                                                        max_len = max_len, \n",
    "                                                        num_words=num_words, \n",
    "                                                        return_sentences=True) \n",
    "X_sentence_val = preprocess_data_embedding(X_raw=X_val, \n",
    "                                                        stem_lem_func=PorterStemmer().stem,\n",
    "                                                        tokenizer=tokenizer, \n",
    "                                                        stop_words=stopwords.words('english'), \n",
    "                                                        min_count=1, # mincount = 1 car on est sur le jeu de validation\n",
    "                                                        max_len = max_len, \n",
    "                                                        num_words=num_words) \n",
    "\n",
    "def embedding_eval_custom_embed(trial):\n",
    "    # Hyperparamètres\n",
    "\n",
    "    ## Embedding\n",
    "    embedding_model = trial.suggest_categorical('embedding_model',list(embedding_dict.keys()))\n",
    "    latent_dim = trial.suggest_int('latent_dim', 30, 150)\n",
    "    window = trial.suggest_int(\"window\", 2, 10)\n",
    "    sg = trial.suggest_int('sg',0,1)\n",
    "\n",
    "    ## Modèle\n",
    "    rnn_size = 64\n",
    "    ## Entrainement\n",
    "    epochs = 50\n",
    "    lr = 1e-3\n",
    "    ## Savepath des poids du modèle\n",
    "    model_savepath = \"./Models/baselineRNN_pre.h5\"\n",
    "\n",
    "\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.log_input(dataset)\n",
    "        mlflow.log_params(params={\n",
    "            'num_words':num_words,               \n",
    "            'max_len': max_len,\n",
    "            'min_count': min_count,\n",
    "            'stemmer': stemmer, \n",
    "            'latent_dim': latent_dim, \n",
    "            'rnn_size': rnn_size, \n",
    "            'embedding_model':embedding_model,\n",
    "            'sg':sg,\n",
    "            'window':window,\n",
    "            'epochs': epochs, \n",
    "            'learning_rate': lr, \n",
    "            \"data_size\": data_size,\n",
    "            \"data_numrows\": data_numrows,\n",
    "        })\n",
    "\n",
    "\n",
    "        # Embedding(custom)\n",
    "        if embedding_model=='Word2Vec':\n",
    "            embedding_model = Word2Vec(\n",
    "                sentences=sentences_train, \n",
    "                vector_size=latent_dim,  # dimension de l’espace latent\n",
    "                window=5,         # taille du contexte\n",
    "                min_count=min_count,      # ignorer les mots trop rares\n",
    "            workers=4,        # parallélisme CPU\n",
    "            sg=sg,              # 1 = skip-gram, 0 = CBOW\n",
    "            epochs=30\n",
    "            )\n",
    "        elif embedding_model=='FastText':\n",
    "            embedding_model = FastText(\n",
    "                sentences=sentences_train, \n",
    "                vector_size=latent_dim, \n",
    "                window=5, \n",
    "                min_count=min_count,\n",
    "                workers=4,\n",
    "                sg=sg,\n",
    "                epochs=30\n",
    "                )\n",
    "\n",
    "\n",
    "        model_vectors = embedding_model.wv\n",
    "        w2v_words = model_vectors.index_to_key\n",
    "\n",
    "        embedding_matrix, vocab_size = build_embedding_matrix(tokenizer=tokenizer,\n",
    "                                          embedding_model=model_vectors, \n",
    "                                          latent_dim=latent_dim\n",
    "                                          )\n",
    "\n",
    "        \n",
    "        # Modèle\n",
    "        model =  build_base_RNN(vocab_size=vocab_size, \n",
    "                        latent_dim=latent_dim,\n",
    "                        input_length=max_len, \n",
    "                        embedding_matrix=embedding_matrix,\n",
    "                        rnn_size = rnn_size)\n",
    "        ## Callbacks\n",
    "        checkpoint = ModelCheckpoint(model_savepath, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min')\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
    "        lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=0, min_lr=1e-5)\n",
    "        callbacks_list = [checkpoint, es, lr_scheduler]\n",
    "        ## Compilation\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "        #Entrainement\n",
    "        with tf.device(\"/GPU:0\"):\n",
    "            history = model.fit(X_sentence_train, y_train, epochs=epochs, batch_size=64, validation_data=(X_sentence_val,y_val), callbacks=callbacks_list, verbose=0)\n",
    "\n",
    "        model.load_weights(model_savepath)\n",
    "\n",
    "        # Prédictions sur le jeu de validation\n",
    "        y_pred_proba = model.predict(X_sentence_val)\n",
    "        y_pred = (y_pred_proba>0.5)\n",
    "\n",
    "\n",
    "        output_dict = postprocess_model_output(y_val, y_pred, y_pred_proba) # voir postprocess_data.py\n",
    "\n",
    "        # Logging des métriques dans MLflow\n",
    "        mlflow.log_metrics(output_dict)\n",
    "        # Matrice de confusion\n",
    "        cm = confusion_matrix(y_val, y_pred, normalize='pred')\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\", ax=ax, )\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.title(\"Confusion Matrix - Validation Set\")\n",
    "        fig.savefig(\"confusion_matrix.png\")\n",
    "        plt.close(fig)\n",
    "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "        #\n",
    "        fig2 = plot_training_history(history,show=False)\n",
    "        fig2.savefig(\"learning_path.png\")\n",
    "        plt.close(fig2)\n",
    "        mlflow.log_artifact(\"learning_path.png\")\n",
    "\n",
    "        # Enregistrement du modèle dans MLflow\n",
    "        mlflow.tensorflow.log_model(model, \"model\")\n",
    "        acc = output_dict[\"Accuracy\"]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095303da",
   "metadata": {},
   "source": [
    "## Definition de l'experiment MLFlow/Optuna\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6fdcac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter optimization with Optuna...\n",
      "Setting up MLflow experiment...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 367, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 465, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1635, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1628, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 367, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 465, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1635, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1628, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n"
     ]
    }
   ],
   "source": [
    "# Création de l'étude Optuna et optimisation\n",
    "print(\"Starting hyperparameter optimization with Optuna...\")\n",
    "print(\"Setting up MLflow experiment...\")\n",
    "mlflow.set_experiment(\"optuna_word_embedding_experiment_custom_embedding\")\n",
    "exp_id = mlflow.get_experiment_by_name(\"optuna_word_embedding_experiment_custom_embedding\").experiment_id\n",
    "\n",
    "experiment_description = (\n",
    "    \"Cette experience contient les différents tests pour le modèle RNN simple. \"\n",
    "    \"Ici on évalue l'impact du type d'embedding custom et de la dimension de l'espace latent sur un modèle avec simpleRNN\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"Sentiment analysis modelling\",\n",
    "    \"model_type\": \"simple-RNN-preprocessing\",\n",
    "    \"team\": \"Ph. Constant\",\n",
    "    \"project_quarter\": \"Q3-2025\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "for key, value in experiment_tags.items():\n",
    "    client.set_experiment_tag(exp_id, key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efe00de",
   "metadata": {},
   "source": [
    "## Lancement de l'optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91597411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-06 17:41:40,435] A new study created in memory with name: no-name-dd804780-6d92-4aab-bb12-a75613882c2e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization trials...\n",
      "Embedding matrix shape: (7727, 84)\n",
      "Words found in pretrained embeddings: 7726/7727 (99.99%)\n",
      "200/200 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 17:44:45 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 17:44:45 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpwxmun93g\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpwxmun93g\\model\\data\\model\\assets\n",
      "2025/10/06 17:44:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 17:44:57,006] Trial 0 finished with value: 0.72015625 and parameters: {'embedding_model': 'FastText', 'latent_dim': 84, 'window': 10, 'sg': 1}. Best is trial 0 with value: 0.72015625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 52)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 17:48:50 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 17:48:50 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp3gq5xsa0\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp3gq5xsa0\\model\\data\\model\\assets\n",
      "2025/10/06 17:49:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 17:49:03,052] Trial 1 finished with value: 0.7125 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 52, 'window': 5, 'sg': 0}. Best is trial 0 with value: 0.72015625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 111)\n",
      "Words found in pretrained embeddings: 7726/7727 (99.99%)\n",
      "200/200 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 17:52:42 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 17:52:42 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpyru126yg\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpyru126yg\\model\\data\\model\\assets\n",
      "2025/10/06 17:52:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 17:52:54,648] Trial 2 finished with value: 0.72046875 and parameters: {'embedding_model': 'FastText', 'latent_dim': 111, 'window': 2, 'sg': 1}. Best is trial 2 with value: 0.72046875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 71)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 17:56:23 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 17:56:23 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp2o0edzhp\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp2o0edzhp\\model\\data\\model\\assets\n",
      "2025/10/06 17:56:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 17:56:33,273] Trial 3 finished with value: 0.71984375 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 71, 'window': 7, 'sg': 1}. Best is trial 2 with value: 0.72046875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 44)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 17:59:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 17:59:26 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp83c39j8n\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp83c39j8n\\model\\data\\model\\assets\n",
      "2025/10/06 17:59:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 17:59:36,349] Trial 4 finished with value: 0.7090625 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 44, 'window': 9, 'sg': 1}. Best is trial 2 with value: 0.72046875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 110)\n",
      "Words found in pretrained embeddings: 7726/7727 (99.99%)\n",
      "200/200 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:02:47 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:02:47 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpj56b5ulp\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpj56b5ulp\\model\\data\\model\\assets\n",
      "2025/10/06 18:02:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:02:56,803] Trial 5 finished with value: 0.7134375 and parameters: {'embedding_model': 'FastText', 'latent_dim': 110, 'window': 6, 'sg': 0}. Best is trial 2 with value: 0.72046875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 94)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:05:57 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:05:57 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpnyk6utt0\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpnyk6utt0\\model\\data\\model\\assets\n",
      "2025/10/06 18:06:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:06:06,165] Trial 6 finished with value: 0.72640625 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 94, 'window': 9, 'sg': 1}. Best is trial 6 with value: 0.72640625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 103)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:09:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:09:13 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpqhpt4enf\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpqhpt4enf\\model\\data\\model\\assets\n",
      "2025/10/06 18:09:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:09:22,853] Trial 7 finished with value: 0.7278125 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 103, 'window': 2, 'sg': 1}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 49)\n",
      "Words found in pretrained embeddings: 7726/7727 (99.99%)\n",
      "200/200 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:12:32 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:12:33 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpx85c1xz_\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpx85c1xz_\\model\\data\\model\\assets\n",
      "2025/10/06 18:12:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:12:42,786] Trial 8 finished with value: 0.710625 and parameters: {'embedding_model': 'FastText', 'latent_dim': 49, 'window': 2, 'sg': 0}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 56)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:15:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:15:56 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpxg5nci4f\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpxg5nci4f\\model\\data\\model\\assets\n",
      "2025/10/06 18:16:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:16:05,463] Trial 9 finished with value: 0.71296875 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 56, 'window': 6, 'sg': 0}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 146)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:18:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:18:28 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpnyzzzfen\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpnyzzzfen\\model\\data\\model\\assets\n",
      "2025/10/06 18:18:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:18:37,306] Trial 10 finished with value: 0.72234375 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 146, 'window': 4, 'sg': 1}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 109)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:21:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:21:15 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpje15zznh\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpje15zznh\\model\\data\\model\\assets\n",
      "2025/10/06 18:21:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:21:23,701] Trial 11 finished with value: 0.72140625 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 109, 'window': 8, 'sg': 1}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 134)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:24:03 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:24:04 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpq42usbvs\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpq42usbvs\\model\\data\\model\\assets\n",
      "2025/10/06 18:24:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:24:14,073] Trial 12 finished with value: 0.72234375 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 134, 'window': 4, 'sg': 1}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 93)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:27:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:27:02 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpftocrkh8\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpftocrkh8\\model\\data\\model\\assets\n",
      "2025/10/06 18:27:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:27:11,524] Trial 13 finished with value: 0.7225 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 93, 'window': 10, 'sg': 1}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 92)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 2s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:30:18 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:30:19 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmphs4t3uc7\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmphs4t3uc7\\model\\data\\model\\assets\n",
      "2025/10/06 18:30:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:30:28,821] Trial 14 finished with value: 0.7125 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 92, 'window': 8, 'sg': 1}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 125)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:33:20 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:33:20 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmps0yaiji2\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmps0yaiji2\\model\\data\\model\\assets\n",
      "2025/10/06 18:33:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:33:29,830] Trial 15 finished with value: 0.71953125 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 125, 'window': 3, 'sg': 1}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 31)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:36:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:36:30 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpkqdzdolo\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpkqdzdolo\\model\\data\\model\\assets\n",
      "2025/10/06 18:36:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:36:38,857] Trial 16 finished with value: 0.7140625 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 31, 'window': 8, 'sg': 1}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 75)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 2s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:39:39 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:39:39 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpjcro7ccm\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpjcro7ccm\\model\\data\\model\\assets\n",
      "2025/10/06 18:39:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:39:47,801] Trial 17 finished with value: 0.7215625 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 75, 'window': 5, 'sg': 0}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 99)\n",
      "Words found in pretrained embeddings: 7726/7727 (99.99%)\n",
      "200/200 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:42:24 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:42:24 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp9_3qubdz\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp9_3qubdz\\model\\data\\model\\assets\n",
      "2025/10/06 18:42:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:42:32,203] Trial 18 finished with value: 0.71546875 and parameters: {'embedding_model': 'FastText', 'latent_dim': 99, 'window': 7, 'sg': 1}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 129)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:45:05 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:45:05 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpgbs5a9fy\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpgbs5a9fy\\model\\data\\model\\assets\n",
      "2025/10/06 18:45:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:45:13,294] Trial 19 finished with value: 0.72625 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 129, 'window': 3, 'sg': 1}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 68)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:47:34 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:47:34 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp4lke1yah\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp4lke1yah\\model\\data\\model\\assets\n",
      "2025/10/06 18:47:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:47:41,867] Trial 20 finished with value: 0.72015625 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 68, 'window': 9, 'sg': 0}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 129)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:50:05 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:50:05 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmplnmq8wxa\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmplnmq8wxa\\model\\data\\model\\assets\n",
      "2025/10/06 18:50:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:50:12,804] Trial 21 finished with value: 0.72671875 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 129, 'window': 3, 'sg': 1}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 122)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:52:32 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:52:32 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpshzzx5dr\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpshzzx5dr\\model\\data\\model\\assets\n",
      "2025/10/06 18:52:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:52:40,006] Trial 22 finished with value: 0.725 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 122, 'window': 3, 'sg': 1}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 147)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:55:03 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:55:03 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp0xqg6vf7\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp0xqg6vf7\\model\\data\\model\\assets\n",
      "2025/10/06 18:55:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:55:11,201] Trial 23 finished with value: 0.7215625 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 147, 'window': 2, 'sg': 1}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 102)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 18:57:55 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 18:57:55 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpgfypws1z\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpgfypws1z\\model\\data\\model\\assets\n",
      "2025/10/06 18:58:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 18:58:03,395] Trial 24 finished with value: 0.724375 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 102, 'window': 4, 'sg': 1}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 117)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 2s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:00:32 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:00:32 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpdc1ar50f\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpdc1ar50f\\model\\data\\model\\assets\n",
      "2025/10/06 19:00:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 19:00:39,752] Trial 25 finished with value: 0.72265625 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 117, 'window': 5, 'sg': 1}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 137)\n",
      "Words found in pretrained embeddings: 7726/7727 (99.99%)\n",
      "200/200 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:03:16 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:03:17 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpgofzba4a\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpgofzba4a\\model\\data\\model\\assets\n",
      "2025/10/06 19:03:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 19:03:24,520] Trial 26 finished with value: 0.72421875 and parameters: {'embedding_model': 'FastText', 'latent_dim': 137, 'window': 3, 'sg': 1}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 82)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:05:53 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:05:53 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpzbyy2kj9\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpzbyy2kj9\\model\\data\\model\\assets\n",
      "2025/10/06 19:06:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 19:06:01,129] Trial 27 finished with value: 0.71375 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 82, 'window': 2, 'sg': 1}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 104)\n",
      "Words found in pretrained embeddings: 7725/7727 (99.97%)\n",
      "200/200 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:08:33 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:08:33 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpeib1buk1\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpeib1buk1\\model\\data\\model\\assets\n",
      "2025/10/06 19:08:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 19:08:42,174] Trial 28 finished with value: 0.7203125 and parameters: {'embedding_model': 'Word2Vec', 'latent_dim': 104, 'window': 7, 'sg': 1}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (7727, 85)\n",
      "Words found in pretrained embeddings: 7726/7727 (99.99%)\n",
      "200/200 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:11:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:11:30 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpo34oz9_u\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpo34oz9_u\\model\\data\\model\\assets\n",
      "2025/10/06 19:11:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-10-06 19:11:37,400] Trial 29 finished with value: 0.7196875 and parameters: {'embedding_model': 'FastText', 'latent_dim': 85, 'window': 10, 'sg': 1}. Best is trial 7 with value: 0.7278125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization completed.\n"
     ]
    }
   ],
   "source": [
    "# Lancement de l'optimisation avec Optuna\n",
    "print(\"Starting optimization trials...\")\n",
    "with mlflow.start_run(run_name=\"optuna_word_embedding_experiment_custom_embedding\"):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(embedding_eval_custom_embed, n_trials=30)\n",
    "    mlflow.log_params(study.best_params)\n",
    "    mlflow.log_metric(\"best_accuracy\", study.best_value)\n",
    "\n",
    "print(\"Optimization completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78809adc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffd878eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 367, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 465, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1635, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1628, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run ID: 95c82edbe4b44614969cdb9308b9e4ee with metrics:\n",
      "Accuracy: 0.7278125\n",
      "F1_negatif: 0.7193038994521431\n",
      "F1_positif: 0.7358204428268122\n",
      "Precision_negatif: 0.7425149700598802\n",
      "Precision_positif: 0.7147908073070124\n",
      "Recall_negatif: 0.6975\n",
      "Recall_positif: 0.758125\n",
      "ROC_AUC: 0.8050172851562499\n",
      "Best run parameters:\n",
      "data_numrows: 32000\n",
      "data_size: 0.02\n",
      "embedding_model: Word2Vec\n",
      "epochs: 50\n",
      "latent_dim: 103\n",
      "learning_rate: 0.001\n",
      "max_len: 30\n",
      "min_count: 2\n",
      "num_words: 30000\n",
      "rnn_size: 64\n",
      "sg: 1\n",
      "stemmer: PorterStemmer\n",
      "window: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'simple_rnn_best_custom_embed' already exists. Creating a new version of this model...\n",
      "2025/10/06 19:11:41 WARNING mlflow.tracking._model_registry.fluent: Run with id 95c82edbe4b44614969cdb9308b9e4ee has no artifacts at artifact path 'model', registering model based on models:/m-0132b36ceda745ff9fc51bb6e1c764fa instead\n",
      "Created version '2' of model 'simple_rnn_best_custom_embed'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting tag data_numrows = 32000 in registered model\n",
      "Setting tag data_size = 0.02 in registered model\n",
      "Setting tag embedding_model = Word2Vec in registered model\n",
      "Setting tag epochs = 50 in registered model\n",
      "Setting tag latent_dim = 103 in registered model\n",
      "Setting tag learning_rate = 0.001 in registered model\n",
      "Setting tag max_len = 30 in registered model\n",
      "Setting tag min_count = 2 in registered model\n",
      "Setting tag num_words = 30000 in registered model\n",
      "Setting tag rnn_size = 64 in registered model\n",
      "Setting tag sg = 1 in registered model\n",
      "Setting tag stemmer = PorterStemmer in registered model\n",
      "Setting tag window = 2 in registered model\n"
     ]
    }
   ],
   "source": [
    "client = MlflowClient(tracking_uri=\"http://localhost:8080\")\n",
    "experiment_id = mlflow.get_experiment_by_name(\"optuna_word_embedding_experiment_custom_embedding\").experiment_id\n",
    "runs = client.search_runs(experiment_id)\n",
    "\n",
    "# Métrique pour sélectionner le meilleur modèle\n",
    "metric_to_optimize = \"Accuracy\" # liste des métriques enregistrées dans postprocess_data.py ou sur l'UI MLflow\n",
    "best_run = max(runs, key=lambda run: run.data.metrics.get(metric_to_optimize, float('-inf')))\n",
    "print(f\"Best run ID: {best_run.info.run_id} with metrics:\")\n",
    "for key, value in best_run.data.metrics.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(f\"Best run parameters:\")\n",
    "for key, value in best_run.data.params.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Enregistrement du meilleur modèle\n",
    "best_model_uri = f\"runs:/{best_run.info.run_id}/model\"\n",
    "registered_model_name = \"simple_rnn_best_custom_embed\"\n",
    "registered_model = mlflow.register_model(best_model_uri, registered_model_name)\n",
    "# Enregistrement des paramètres sous forme de tags dans le modèle enregistré\n",
    "for key, value in best_run.data.params.items():\n",
    "    print(f\"Setting tag {key} = {value} in registered model\")\n",
    "    client.set_model_version_tag(\n",
    "        name=registered_model_name,\n",
    "        version=str(registered_model.version),\n",
    "        key=str(key),\n",
    "        value=str(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b7c999",
   "metadata": {},
   "source": [
    "# Experimentation sur les embeddings (préentrainés)\n",
    "\n",
    "Les embeddings pré-entrainés ont été entrainés sur un très grand nombre de tweets et prennent donc en compte un très grand nombre de situations. On peut donc se passer de la phase de stemming et garder les stopwords. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128a8c3c",
   "metadata": {},
   "source": [
    "## Préparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f259b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "# Word2Vec Google News\n",
    "w2v_google = api.load(\"word2vec-google-news-300\")  # KeyedVectors\n",
    "\n",
    "# FastText wiki-news subwords-300\n",
    "ft_wiki = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "\n",
    "# GloVe Twitter (par exemple 200 dimensions)\n",
    "glove_tw200 = api.load(\"glove-twitter-200\")\n",
    "glove_tw100 = api.load(\"glove-twitter-100\")\n",
    "glove_tw50  = api.load(\"glove-twitter-50\")\n",
    "glove_tw25  = api.load(\"glove-twitter-25\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b959004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = {'Word2Vec_google':w2v_google, \n",
    "                  'FastText_wiki':ft_wiki,\n",
    "                  'Glove_twitter_200':glove_tw200, \n",
    "                  'Glove_twitter_100':glove_tw100, \n",
    "                  'Glove_twitter_50':glove_tw50, \n",
    "                  'Glove_twitter_25':glove_tw25\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6540f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prétraitement\n",
    "min_count = 2\n",
    "num_words = 30000\n",
    "max_len   = 30\n",
    "# Prétraitement\n",
    "X_sentence_train, tokenizer, sentences_train = preprocess_data_embedding(X_raw=X_train, \n",
    "                                                        stem_lem_func=None,\n",
    "                                                        tokenizer=None, \n",
    "                                                        stop_words=None, \n",
    "                                                        min_count=min_count,\n",
    "                                                        max_len = max_len, \n",
    "                                                        num_words=num_words, \n",
    "                                                        return_sentences=True) \n",
    "X_sentence_val = preprocess_data_embedding(X_raw=X_val, \n",
    "                                                        stem_lem_func=None,\n",
    "                                                        tokenizer=tokenizer, \n",
    "                                                        stop_words=None, \n",
    "                                                        min_count=1, # mincount = 1 car on est sur le jeu de validation\n",
    "                                                        max_len = max_len, \n",
    "                                                        num_words=num_words) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab8767c",
   "metadata": {},
   "source": [
    "## Fonction de base "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6212a43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamètres\n",
    "\n",
    "## Modèle\n",
    "rnn_size = 64\n",
    "## Entrainement\n",
    "epochs = 50\n",
    "lr = 1e-3\n",
    "## Savepath des poids du modèle\n",
    "model_savepath = \"./Models/baselineRNN_pretrained_embed.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d87b166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embed_experiment(embedding_name):\n",
    "     with mlflow.start_run():\n",
    "        mlflow.log_input(dataset)\n",
    "        latent_dim = embedding_dict[embedding_name].vector_size\n",
    "        mlflow.log_params(params={\n",
    "            'num_words':num_words,               \n",
    "            'max_len': max_len,\n",
    "            'min_count': min_count,\n",
    "            'stemmer': 'None', \n",
    "            'latent_dim': latent_dim, \n",
    "            'rnn_size': rnn_size, \n",
    "            'epochs': epochs, \n",
    "            'learning_rate': lr,\n",
    "            'embedding_name':embedding_name,\n",
    "            \"data_size\": data_size,\n",
    "            \"data_numrows\": data_numrows,\n",
    "        })\n",
    "\n",
    "\n",
    "        model_vectors = embedding_dict[embedding_name]\n",
    "\n",
    "        embedding_matrix, vocab_size = build_embedding_matrix(tokenizer=tokenizer,\n",
    "                                          embedding_model=model_vectors, \n",
    "                                          latent_dim=latent_dim\n",
    "                                          )\n",
    "\n",
    "        # Modèle\n",
    "        model =  build_base_RNN(vocab_size=vocab_size, \n",
    "                        latent_dim=latent_dim,\n",
    "                        input_length=max_len, \n",
    "                        embedding_matrix=embedding_matrix,\n",
    "                        rnn_size = rnn_size)\n",
    "        ## Callbacks\n",
    "        checkpoint = ModelCheckpoint(model_savepath, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min')\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
    "        lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=0, min_lr=1e-5)\n",
    "        callbacks_list = [checkpoint, es, lr_scheduler]\n",
    "        ## Compilation\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "        #Entrainement\n",
    "        with tf.device(\"/GPU:0\"):\n",
    "            history = model.fit(X_sentence_train, y_train, epochs=epochs, batch_size=64, validation_data=(X_sentence_val,y_val), callbacks=callbacks_list, verbose=0)\n",
    "\n",
    "        model.load_weights(model_savepath)\n",
    "\n",
    "                # Prédictions sur le jeu de validation\n",
    "        y_pred_proba = model.predict(X_sentence_val)\n",
    "        y_pred = (y_pred_proba>0.5)\n",
    "\n",
    "\n",
    "        output_dict = postprocess_model_output(y_val, y_pred, y_pred_proba) # voir postprocess_data.py\n",
    "\n",
    "        # Logging des métriques dans MLflow\n",
    "        mlflow.log_metrics(output_dict)\n",
    "        # Matrice de confusion\n",
    "        cm = confusion_matrix(y_val, y_pred, normalize='pred')\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\", ax=ax, )\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.title(\"Confusion Matrix - Validation Set\")\n",
    "        fig.savefig(\"confusion_matrix.png\")\n",
    "        plt.close(fig)\n",
    "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "        #\n",
    "        fig2 = plot_training_history(history,show=False)\n",
    "        fig2.savefig(\"learning_path.png\")\n",
    "        plt.close(fig2)\n",
    "        mlflow.log_artifact(\"learning_path.png\")\n",
    "\n",
    "        # Enregistrement du modèle dans MLflow\n",
    "        mlflow.tensorflow.log_model(model, \"model\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d50b14",
   "metadata": {},
   "source": [
    "## Définition de l'experiment dans MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "079ae708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 367, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 465, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1635, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1628, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 367, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 465, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1635, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1628, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter optimization with Optuna...\n",
      "Setting up MLflow experiment...\n"
     ]
    }
   ],
   "source": [
    "# Création de l'étude Optuna et optimisation\n",
    "print(\"Starting hyperparameter optimization with Optuna...\")\n",
    "print(\"Setting up MLflow experiment...\")\n",
    "mlflow.set_experiment(\"word_embedding_experiment_pretrained_embedding\")\n",
    "exp_id = mlflow.get_experiment_by_name(\"word_embedding_experiment_pretrained_embedding\").experiment_id\n",
    "\n",
    "experiment_description = (\n",
    "    \"Cette experience contient les différents tests pour le modèle RNN simple. \"\n",
    "    \"Ici on teste plusieurs embeddings préentrainées sur de larges corpora, beaucoup d'attentes par rapport aux embeddings avec Glove entrainés sur des tweets\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"Sentiment analysis modelling\",\n",
    "    \"model_type\": \"simple-RNN-pretrained-embeddings\",\n",
    "    \"team\": \"Ph. Constant\",\n",
    "    \"project_quarter\": \"Q3-2025\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "for key, value in experiment_tags.items():\n",
    "    client.set_experiment_tag(exp_id, key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0697ce9",
   "metadata": {},
   "source": [
    "## Lancement de l'experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de3a8135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with Word2Vec_google\n",
      "Embedding matrix shape: (9616, 300)\n",
      "Words found in pretrained embeddings: 8930/9616 (92.87%)\n",
      "200/200 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:20:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:20:54 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp0l012xn1\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp0l012xn1\\model\\data\\model\\assets\n",
      "2025/10/06 19:21:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with FastText_wiki\n",
      "Embedding matrix shape: (9616, 300)\n",
      "Words found in pretrained embeddings: 9173/9616 (95.39%)\n",
      "200/200 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:24:05 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:24:05 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpfe_a6jft\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpfe_a6jft\\model\\data\\model\\assets\n",
      "2025/10/06 19:24:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with Glove_twitter_200\n",
      "Embedding matrix shape: (9616, 200)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n",
      "200/200 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:26:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:26:21 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpmzrdx76b\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpmzrdx76b\\model\\data\\model\\assets\n",
      "2025/10/06 19:26:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with Glove_twitter_100\n",
      "Embedding matrix shape: (9616, 100)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n",
      "200/200 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:28:15 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:28:15 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpgq0orbrf\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpgq0orbrf\\model\\data\\model\\assets\n",
      "2025/10/06 19:28:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with Glove_twitter_50\n",
      "Embedding matrix shape: (9616, 50)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n",
      "200/200 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:30:35 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:30:35 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmppy1fe1ys\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmppy1fe1ys\\model\\data\\model\\assets\n",
      "2025/10/06 19:30:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with Glove_twitter_25\n",
      "Embedding matrix shape: (9616, 25)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n",
      "200/200 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:33:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:33:52 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpv3sbe_od\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpv3sbe_od\\model\\data\\model\\assets\n",
      "2025/10/06 19:34:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "for embedding_name in list(embedding_dict.keys()):\n",
    "    \n",
    "    print(f\"Running test with {embedding_name}\")\n",
    "    pretrained_embed_experiment(embedding_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa14dca",
   "metadata": {},
   "source": [
    "## Enregistrement du meilleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "abb9d454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 367, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 465, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1635, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1628, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run ID: ce06b66ec4ff48e6a994d2485c63701f with metrics:\n",
      "Accuracy: 0.795875\n",
      "F1_negatif: 0.7963459499906467\n",
      "F1_positif: 0.7954018668170143\n",
      "Precision_negatif: 0.7945128779395296\n",
      "Precision_positif: 0.7972497802335803\n",
      "Recall_negatif: 0.7981875\n",
      "Recall_positif: 0.7935625\n",
      "ROC_AUC: 0.874631751953125\n",
      "Best run parameters:\n",
      "embedding_name: Glove_twitter_200\n",
      "epochs: 50\n",
      "latent_dim: 200\n",
      "learning_rate: 0.001\n",
      "max_len: 30\n",
      "min_count: 2\n",
      "num_words: 20000\n",
      "rnn_size: 64\n",
      "stemmer: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'simple_rnn_best_pre' already exists. Creating a new version of this model...\n",
      "2025/10/06 19:34:05 WARNING mlflow.tracking._model_registry.fluent: Run with id ce06b66ec4ff48e6a994d2485c63701f has no artifacts at artifact path 'model', registering model based on models:/m-6b8da83843cc4061a7b1edb36b9eb5f4 instead\n",
      "Created version '4' of model 'simple_rnn_best_pre'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting tag embedding_name = Glove_twitter_200 in registered model\n",
      "Setting tag epochs = 50 in registered model\n",
      "Setting tag latent_dim = 200 in registered model\n",
      "Setting tag learning_rate = 0.001 in registered model\n",
      "Setting tag max_len = 30 in registered model\n",
      "Setting tag min_count = 2 in registered model\n",
      "Setting tag num_words = 20000 in registered model\n",
      "Setting tag rnn_size = 64 in registered model\n",
      "Setting tag stemmer = None in registered model\n"
     ]
    }
   ],
   "source": [
    "client = MlflowClient(tracking_uri=\"http://localhost:8080\")\n",
    "experiment_id = mlflow.get_experiment_by_name(\"word_embedding_experiment_pretrained_embedding\").experiment_id\n",
    "runs = client.search_runs(experiment_id)\n",
    "\n",
    "# Métrique pour sélectionner le meilleur modèle\n",
    "metric_to_optimize = \"Accuracy\" # liste des métriques enregistrées dans postprocess_data.py ou sur l'UI MLflow\n",
    "best_run = max(runs, key=lambda run: run.data.metrics.get(metric_to_optimize, float('-inf')))\n",
    "print(f\"Best run ID: {best_run.info.run_id} with metrics:\")\n",
    "for key, value in best_run.data.metrics.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(f\"Best run parameters:\")\n",
    "for key, value in best_run.data.params.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Enregistrement du meilleur modèle\n",
    "best_model_uri = f\"runs:/{best_run.info.run_id}/model\"\n",
    "registered_model_name = \"simple_rnn_best_pre\"\n",
    "registered_model = mlflow.register_model(best_model_uri, registered_model_name)\n",
    "# Enregistrement des paramètres sous forme de tags dans le modèle enregistré\n",
    "for key, value in best_run.data.params.items():\n",
    "    print(f\"Setting tag {key} = {value} in registered model\")\n",
    "    client.set_model_version_tag(\n",
    "        name=registered_model_name,\n",
    "        version=str(registered_model.version),\n",
    "        key=str(key),\n",
    "        value=str(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579521f6",
   "metadata": {},
   "source": [
    "# Comparaison des différentes couches de notre réseau de neurones : SimpleRNN vs GRU vs LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5966ad3",
   "metadata": {},
   "source": [
    "## Préparation \n",
    "\n",
    "On reprend les paramètres d'embedding de la meilleure run sur embeddings customs et embeddings préentrainés. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45154a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (9616, 200)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n"
     ]
    }
   ],
   "source": [
    "## Prétraitement\n",
    "min_count = 2\n",
    "num_words = 20000\n",
    "max_len   = 30\n",
    "# Prétraitement\n",
    "X_sentence_train, tokenizer, sentences_train = preprocess_data_embedding(X_raw=X_train, \n",
    "                                                        stem_lem_func=None,\n",
    "                                                        tokenizer=None, \n",
    "                                                        stop_words=None, \n",
    "                                                        min_count=min_count,\n",
    "                                                        max_len = max_len, \n",
    "                                                        num_words=num_words, \n",
    "                                                        return_sentences=True) \n",
    "X_sentence_val = preprocess_data_embedding(X_raw=X_val, \n",
    "                                                        stem_lem_func=None,\n",
    "                                                        tokenizer=tokenizer, \n",
    "                                                        stop_words=None, \n",
    "                                                        min_count=1, # mincount = 1 car on est sur le jeu de validation\n",
    "                                                        max_len = max_len, \n",
    "                                                        num_words=num_words) \n",
    "\n",
    "\n",
    "model_vectors = glove_tw200\n",
    "latent_dim = glove_tw200.vector_size\n",
    "\n",
    "embedding_matrix, vocab_size = build_embedding_matrix(tokenizer=tokenizer,\n",
    "                                embedding_model=model_vectors, \n",
    "                                latent_dim=latent_dim\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80933f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Source.preprocess_data import *\n",
    "rnn_layer_name_list = ['SimpleRNN','GRU','LSTM']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a066a0f",
   "metadata": {},
   "source": [
    "## Fonction de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "765bce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modèle\n",
    "rnn_size = 64\n",
    "## Entrainement\n",
    "epochs = 50\n",
    "lr = 1e-3\n",
    "## Savepath des poids du modèle\n",
    "\n",
    "def rnn_layer_experiment(rnn_layer_name):\n",
    "     with mlflow.start_run():\n",
    "        mlflow.log_input(dataset)\n",
    "\n",
    "        mlflow.log_params(params={\n",
    "            'num_words':num_words,               \n",
    "            'max_len': max_len,\n",
    "            'min_count': min_count,\n",
    "            'stemmer': 'None', \n",
    "            'latent_dim': latent_dim, \n",
    "            'rnn_size': rnn_size, \n",
    "            'epochs': epochs, \n",
    "            'learning_rate': lr,\n",
    "            'embedding_name':'Glove_twitter_200',\n",
    "            'rnn_layer_name':rnn_layer_name,\n",
    "            \"data_size\": data_size,\n",
    "            \"data_numrows\": data_numrows,\n",
    "        })\n",
    "        model_savepath = \"./Models/\"+rnn_layer_name+\"_model_exp.h5\"\n",
    "        # Modèle\n",
    "        if rnn_layer_name == 'SimpleRNN':\n",
    "            model =  build_base_RNN(vocab_size=vocab_size, \n",
    "                            latent_dim=latent_dim,\n",
    "                            input_length=max_len, \n",
    "                            embedding_matrix=embedding_matrix,\n",
    "                            rnn_size = rnn_size)\n",
    "        elif rnn_layer_name == 'GRU':\n",
    "            model = build_gru_RNN(vocab_size=vocab_size, \n",
    "                            latent_dim=latent_dim,\n",
    "                            input_length=max_len, \n",
    "                            embedding_matrix=embedding_matrix,\n",
    "                            rnn_size = rnn_size)\n",
    "        elif rnn_layer_name=='LSTM':\n",
    "            model = build_lstm_RNN(vocab_size=vocab_size, \n",
    "                            latent_dim=latent_dim,\n",
    "                            input_length=max_len, \n",
    "                            embedding_matrix=embedding_matrix,\n",
    "                            rnn_size = rnn_size)\n",
    "        ## Callbacks\n",
    "        checkpoint = ModelCheckpoint(model_savepath, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min')\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
    "        lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=0, min_lr=1e-5)\n",
    "        callbacks_list = [checkpoint, es, lr_scheduler]\n",
    "        ## Compilation\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "        #Entrainement\n",
    "        with tf.device(\"/GPU:0\"):\n",
    "            history = model.fit(X_sentence_train, y_train, epochs=epochs, batch_size=64, validation_data=(X_sentence_val,y_val), callbacks=callbacks_list, verbose=0)\n",
    "\n",
    "        model.load_weights(model_savepath)\n",
    "\n",
    "                # Prédictions sur le jeu de validation\n",
    "        y_pred_proba = model.predict(X_sentence_val)\n",
    "        y_pred = (y_pred_proba>0.5)\n",
    "\n",
    "\n",
    "        output_dict = postprocess_model_output(y_val, y_pred, y_pred_proba) # voir postprocess_data.py\n",
    "\n",
    "        # Logging des métriques dans MLflow\n",
    "        mlflow.log_metrics(output_dict)\n",
    "        # Matrice de confusion\n",
    "        cm = confusion_matrix(y_val, y_pred, normalize='pred')\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\", ax=ax, )\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.title(\"Confusion Matrix - Validation Set\")\n",
    "        fig.savefig(\"confusion_matrix.png\")\n",
    "        plt.close(fig)\n",
    "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "        #\n",
    "        fig2 = plot_training_history(history,show=False)\n",
    "        fig2.savefig(\"learning_path.png\")\n",
    "        plt.close(fig2)\n",
    "        mlflow.log_artifact(\"learning_path.png\")\n",
    "\n",
    "        # Enregistrement du modèle dans MLflow\n",
    "        mlflow.tensorflow.log_model(model, \"model\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdd9607",
   "metadata": {},
   "source": [
    "## Definition de l'experiment dans MLFLow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a9394a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 367, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 465, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1635, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1628, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 367, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 465, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1635, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1628, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up MLflow experiment...\n"
     ]
    }
   ],
   "source": [
    "# Création de l'étude Optuna et optimisation\n",
    "print(\"Setting up MLflow experiment...\")\n",
    "mlflow.set_experiment(\"rnn_layer_experiment_pretrained_embedding\")\n",
    "exp_id = mlflow.get_experiment_by_name(\"rnn_layer_experiment_pretrained_embedding\").experiment_id\n",
    "\n",
    "experiment_description = (\n",
    "    \"Comparaison des impact des types de cellules RNN utilisées : SimpleRNN, GRU et LSTM \"\n",
    "    \"\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"Sentiment analysis modelling\",\n",
    "    \"model_type\": \"RNN_types-pretrained-embeddings\",\n",
    "    \"team\": \"Ph. Constant\",\n",
    "    \"project_quarter\": \"Q3-2025\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "for key, value in experiment_tags.items():\n",
    "    client.set_experiment_tag(exp_id, key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362e75c9",
   "metadata": {},
   "source": [
    "## Lancement de l'expériment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af58cb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with SimpleRNN\n",
      "200/200 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:36:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:36:17 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmphoourp89\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmphoourp89\\model\\data\\model\\assets\n",
      "2025/10/06 19:36:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with GRU\n",
      "200/200 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:38:04 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:38:04 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpobygs7eb\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpobygs7eb\\model\\data\\model\\assets\n",
      "2025/10/06 19:38:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with LSTM\n",
      "200/200 [==============================] - 2s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:40:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:40:02 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpy3apnxxi\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpy3apnxxi\\model\\data\\model\\assets\n",
      "2025/10/06 19:40:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "for rnn_layer_name in rnn_layer_name_list:\n",
    "    \n",
    "    print(f\"Running test with {rnn_layer_name}\")\n",
    "    rnn_layer_experiment(rnn_layer_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6f7e94",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb8369b0",
   "metadata": {},
   "source": [
    "# Retour sur la longueur des séquences     \n",
    "\n",
    "Ici on va revenir sur la longueur des séquences utilisées car LSTM permet de garder des séquences plus longues sans pour autant avoir d'évanescence de gradient. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb59f6",
   "metadata": {},
   "source": [
    "## Fonction de base "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c298ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Modèle\n",
    "rnn_size = 64\n",
    "## Entrainement\n",
    "epochs = 50\n",
    "lr = 1e-3\n",
    "## Savepath des poids du modèle\n",
    "\n",
    "def lstm_maxlen_experiment(max_len):\n",
    "     with mlflow.start_run():\n",
    "        latent_dim = glove_tw200.vector_size\n",
    "        mlflow.log_input(dataset)\n",
    "        mlflow.log_params(params={\n",
    "            'num_words':num_words,               \n",
    "            'max_len': max_len,\n",
    "            'min_count': min_count,\n",
    "            'stemmer': 'None', \n",
    "            'latent_dim': latent_dim, \n",
    "            'rnn_size': rnn_size, \n",
    "            'epochs': epochs, \n",
    "            'learning_rate': lr,\n",
    "            'embedding_name':'Glove_twitter_200',\n",
    "            'rnn_layer_name':'LSTM',\n",
    "            \"data_size\": data_size,\n",
    "            \"data_numrows\": data_numrows,\n",
    "        })\n",
    "\n",
    "        ## Prétraitement\n",
    "\n",
    "        # Prétraitement\n",
    "        X_sentence_train, tokenizer, sentences_train = preprocess_data_embedding(X_raw=X_train, \n",
    "                                                        stem_lem_func=None,\n",
    "                                                        tokenizer=None, \n",
    "                                                        stop_words=None, \n",
    "                                                        min_count=min_count,\n",
    "                                                        max_len = max_len, \n",
    "                                                        num_words=num_words, \n",
    "                                                        return_sentences=True) \n",
    "        X_sentence_val = preprocess_data_embedding(X_raw=X_val, \n",
    "                                                        stem_lem_func=None,\n",
    "                                                        tokenizer=tokenizer, \n",
    "                                                        stop_words=None, \n",
    "                                                        min_count=1, # mincount = 1 car on est sur le jeu de validation\n",
    "                                                        max_len = max_len, \n",
    "                                                        num_words=num_words) \n",
    "\n",
    "\n",
    "        model_vectors = glove_tw200\n",
    "\n",
    "        embedding_matrix, vocab_size = build_embedding_matrix(tokenizer=tokenizer,\n",
    "                                embedding_model=model_vectors, \n",
    "                                latent_dim=latent_dim\n",
    "                              )\n",
    "        model_savepath = f\"./Models/{rnn_layer_name}_model_exp_len{max_len}.h5\"\n",
    "        # Modèle\n",
    "\n",
    "        model = build_lstm_RNN(vocab_size=vocab_size, \n",
    "                            latent_dim=latent_dim,\n",
    "                            input_length=max_len, \n",
    "                            embedding_matrix=embedding_matrix,\n",
    "                            rnn_size = rnn_size)\n",
    "        ## Callbacks\n",
    "        checkpoint = ModelCheckpoint(model_savepath, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min')\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
    "        lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=0, min_lr=1e-5)\n",
    "        callbacks_list = [checkpoint, es, lr_scheduler]\n",
    "        ## Compilation\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "        #Entrainement\n",
    "        with tf.device(\"/GPU:0\"):\n",
    "            history = model.fit(X_sentence_train, y_train, epochs=epochs, batch_size=64, validation_data=(X_sentence_val,y_val), callbacks=callbacks_list, verbose=0)\n",
    "\n",
    "        model.load_weights(model_savepath)\n",
    "\n",
    "                # Prédictions sur le jeu de validation\n",
    "        y_pred_proba = model.predict(X_sentence_val)\n",
    "        y_pred = (y_pred_proba>0.5)\n",
    "\n",
    "\n",
    "        output_dict = postprocess_model_output(y_val, y_pred, y_pred_proba) # voir postprocess_data.py\n",
    "\n",
    "        # Logging des métriques dans MLflow\n",
    "        mlflow.log_metrics(output_dict)\n",
    "        # Matrice de confusion\n",
    "        cm = confusion_matrix(y_val, y_pred, normalize='pred')\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\", ax=ax, )\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.title(\"Confusion Matrix - Validation Set\")\n",
    "        fig.savefig(\"confusion_matrix.png\")\n",
    "        plt.close(fig)\n",
    "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "        #\n",
    "        fig2 = plot_training_history(history,show=False)\n",
    "        fig2.savefig(\"learning_path.png\")\n",
    "        plt.close(fig2)\n",
    "        mlflow.log_artifact(\"learning_path.png\")\n",
    "\n",
    "        # Enregistrement du modèle dans MLflow\n",
    "        mlflow.tensorflow.log_model(model, \"model\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5404a5",
   "metadata": {},
   "source": [
    "## Experiment MLFLow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bdc6830b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 367, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 465, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1635, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1628, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 367, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 465, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1635, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1628, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up MLflow experiment...\n"
     ]
    }
   ],
   "source": [
    "# Création de l'étude Optuna et optimisation\n",
    "print(\"Setting up MLflow experiment...\")\n",
    "mlflow.set_experiment(\"lstm_maxlen_experiment\")\n",
    "exp_id = mlflow.get_experiment_by_name(\"lstm_maxlen_experiment\").experiment_id\n",
    "\n",
    "experiment_description = (\n",
    "    \"Comparaison des impact des types de cellules RNN utilisées : SimpleRNN, GRU et LSTM \"\n",
    "    \"\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"Sentiment analysis modelling\",\n",
    "    \"model_type\": \"LSTM_pretrained_embedding\",\n",
    "    \"team\": \"Ph. Constant\",\n",
    "    \"project_quarter\": \"Q3-2025\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "for key, value in experiment_tags.items():\n",
    "    client.set_experiment_tag(exp_id, key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f405b051",
   "metadata": {},
   "source": [
    "## Lancement de l'experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c0c6c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with sequence length of 30 tokens\n",
      "Embedding matrix shape: (9616, 200)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n",
      "200/200 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:42:03 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:42:03 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmprbce8r0f\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmprbce8r0f\\model\\data\\model\\assets\n",
      "2025/10/06 19:42:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with sequence length of 35 tokens\n",
      "Embedding matrix shape: (9616, 200)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n",
      "200/200 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:44:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:44:11 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpqzjtp3nh\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpqzjtp3nh\\model\\data\\model\\assets\n",
      "2025/10/06 19:44:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with sequence length of 40 tokens\n",
      "Embedding matrix shape: (9616, 200)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n",
      "200/200 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:46:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:46:03 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpuvvczdl0\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpuvvczdl0\\model\\data\\model\\assets\n",
      "2025/10/06 19:46:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with sequence length of 45 tokens\n",
      "Embedding matrix shape: (9616, 200)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n",
      "200/200 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:48:03 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:48:03 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp82smw54e\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp82smw54e\\model\\data\\model\\assets\n",
      "2025/10/06 19:48:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with sequence length of 50 tokens\n",
      "Embedding matrix shape: (9616, 200)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n",
      "200/200 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:50:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:50:14 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp7pc90lw4\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp7pc90lw4\\model\\data\\model\\assets\n",
      "2025/10/06 19:50:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with sequence length of 55 tokens\n",
      "Embedding matrix shape: (9616, 200)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n",
      "200/200 [==============================] - 3s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:53:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:53:02 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp7q0nw3h4\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp7q0nw3h4\\model\\data\\model\\assets\n",
      "2025/10/06 19:53:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with sequence length of 60 tokens\n",
      "Embedding matrix shape: (9616, 200)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n",
      "200/200 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:55:47 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:55:47 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpr194bjsa\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpr194bjsa\\model\\data\\model\\assets\n",
      "2025/10/06 19:56:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with sequence length of 65 tokens\n",
      "Embedding matrix shape: (9616, 200)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n",
      "200/200 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 19:58:31 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 19:58:31 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpm2tl1wyw\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpm2tl1wyw\\model\\data\\model\\assets\n",
      "2025/10/06 19:58:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with sequence length of 70 tokens\n",
      "Embedding matrix shape: (9616, 200)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n",
      "200/200 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 20:01:47 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 20:01:47 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp604ozebu\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp604ozebu\\model\\data\\model\\assets\n",
      "2025/10/06 20:02:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with sequence length of 75 tokens\n",
      "Embedding matrix shape: (9616, 200)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n",
      "200/200 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 20:05:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 20:05:11 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp_nacz27e\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp_nacz27e\\model\\data\\model\\assets\n",
      "2025/10/06 20:05:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with sequence length of 80 tokens\n",
      "Embedding matrix shape: (9616, 200)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n",
      "200/200 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 20:08:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 20:08:30 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmprcbsl3pq\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmprcbsl3pq\\model\\data\\model\\assets\n",
      "2025/10/06 20:08:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with sequence length of 85 tokens\n",
      "Embedding matrix shape: (9616, 200)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n",
      "200/200 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 20:11:58 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 20:11:59 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpl6hwf5_3\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpl6hwf5_3\\model\\data\\model\\assets\n",
      "2025/10/06 20:12:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with sequence length of 90 tokens\n",
      "Embedding matrix shape: (9616, 200)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n",
      "200/200 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 20:15:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 20:15:30 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpij4f0m5k\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmpij4f0m5k\\model\\data\\model\\assets\n",
      "2025/10/06 20:15:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with sequence length of 95 tokens\n",
      "Embedding matrix shape: (9616, 200)\n",
      "Words found in pretrained embeddings: 9452/9616 (98.29%)\n",
      "200/200 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/06 20:19:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/10/06 20:19:30 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_14_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp1756tp5f\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp1756tp5f\\model\\data\\model\\assets\n",
      "2025/10/06 20:19:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "for max_len in list(range(30,100,5)):\n",
    "    \n",
    "    print(f\"Running test with sequence length of {max_len} tokens\")\n",
    "    lstm_maxlen_experiment(max_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecba592",
   "metadata": {},
   "source": [
    "## Enregistrement du mailleur modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "406df028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 367, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 465, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1635, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1628, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\ProgramData\\anaconda3\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run ID: b63acc4f64914a5fb77ab6b26a974e13 with metrics:\n",
      "Accuracy: 0.81365625\n",
      "F1_negatif: 0.811518159117489\n",
      "F1_positif: 0.8157463770355035\n",
      "Precision_negatif: 0.8209375199846518\n",
      "Precision_positif: 0.8066980382570433\n",
      "Recall_negatif: 0.8023125\n",
      "Recall_positif: 0.825\n",
      "ROC_AUC: 0.89485159765625\n",
      "Best run parameters:\n",
      "embedding_name: Glove_twitter_200\n",
      "epochs: 50\n",
      "latent_dim: 200\n",
      "learning_rate: 0.001\n",
      "max_len: 50\n",
      "min_count: 2\n",
      "num_words: 20000\n",
      "rnn_layer_name: LSTM\n",
      "rnn_size: 64\n",
      "stemmer: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'lstm_maxlen_best' already exists. Creating a new version of this model...\n",
      "2025/10/06 20:19:55 WARNING mlflow.tracking._model_registry.fluent: Run with id b63acc4f64914a5fb77ab6b26a974e13 has no artifacts at artifact path 'model', registering model based on models:/m-612a40cdbb1d4774b96429b02b0740f8 instead\n",
      "Created version '2' of model 'lstm_maxlen_best'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting tag embedding_name = Glove_twitter_200 in registered model\n",
      "Setting tag epochs = 50 in registered model\n",
      "Setting tag latent_dim = 200 in registered model\n",
      "Setting tag learning_rate = 0.001 in registered model\n",
      "Setting tag max_len = 50 in registered model\n",
      "Setting tag min_count = 2 in registered model\n",
      "Setting tag num_words = 20000 in registered model\n",
      "Setting tag rnn_layer_name = LSTM in registered model\n",
      "Setting tag rnn_size = 64 in registered model\n",
      "Setting tag stemmer = None in registered model\n"
     ]
    }
   ],
   "source": [
    "client = MlflowClient(tracking_uri=\"http://localhost:8080\")\n",
    "experiment_id = mlflow.get_experiment_by_name(\"lstm_maxlen_experiment\").experiment_id\n",
    "runs = client.search_runs(experiment_id)\n",
    "\n",
    "# Métrique pour sélectionner le meilleur modèle\n",
    "metric_to_optimize = \"Accuracy\" # liste des métriques enregistrées dans postprocess_data.py ou sur l'UI MLflow\n",
    "best_run = max(runs, key=lambda run: run.data.metrics.get(metric_to_optimize, float('-inf')))\n",
    "print(f\"Best run ID: {best_run.info.run_id} with metrics:\")\n",
    "for key, value in best_run.data.metrics.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(f\"Best run parameters:\")\n",
    "for key, value in best_run.data.params.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Enregistrement du meilleur modèle\n",
    "best_model_uri = f\"runs:/{best_run.info.run_id}/model\"\n",
    "registered_model_name = \"lstm_maxlen_best\"\n",
    "registered_model = mlflow.register_model(best_model_uri, registered_model_name)\n",
    "# Enregistrement des paramètres sous forme de tags dans le modèle enregistré\n",
    "for key, value in best_run.data.params.items():\n",
    "    print(f\"Setting tag {key} = {value} in registered model\")\n",
    "    client.set_model_version_tag(\n",
    "        name=registered_model_name,\n",
    "        version=str(registered_model.version),\n",
    "        key=str(key),\n",
    "        value=str(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3d788b",
   "metadata": {},
   "source": [
    "Quand on regarde les améliorations obtenues en augmentant la longueur des séquences, il n'est pas réellement pertinent d'augmenter la longueur des séquences au delà de 50 tokens. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_env_P7_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
