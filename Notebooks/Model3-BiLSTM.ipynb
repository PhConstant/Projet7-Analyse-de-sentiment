{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf76efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n",
      "Num GPUs Available:  1\n",
      "GPUs disponibles : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Version TF : 2.10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import TextVectorization, Embedding, SimpleRNN, Dense, LSTM, Flatten\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim.downloader as gensim_downloader\n",
    "import gensim\n",
    "import multiprocessing\n",
    "from mlflow import MlflowClient\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from Source.preprocess_data import *  ## import all functions from preprocess_data.py\n",
    "from Source.postprocess_data import * ## import all functions from postprocess_data.py\n",
    "from Source.utils import *  ## import all functions from utils.py\n",
    "import nltk\n",
    "import optuna\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import TweetTokenizer, WordPunctTokenizer, RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer, LancasterStemmer, SnowballStemmer\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "nw = multiprocessing.cpu_count()\n",
    "\n",
    "\n",
    "\n",
    "client = MlflowClient(tracking_uri=\"http://localhost:8080\")\n",
    "os.environ[\"TF_KERAS\"]='1'\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPUs disponibles :\", tf.config.list_physical_devices(\"GPU\"))\n",
    "print(\"Version TF :\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85ec2be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 160000 rows\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/AI+Engineer/Project+7%C2%A0-+D%C3%A9tectez+les+Bad+Buzz+gr%C3%A2ce+au+Deep+Learning/sentiment140.zip',\n",
    "                header=None,\n",
    "                compression='zip',\n",
    "                encoding='cp1252')\n",
    "\n",
    "df.columns = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "\n",
    "sample_df, _ = train_test_split(df, test_size=0.9, random_state=42, stratify=df['target'])\n",
    "sample_df = sample_df.reset_index(drop=True)\n",
    "print(f\"Sample size: {sample_df.shape[0]} rows\")\n",
    "# On ne garde que les colonnes 'target' et 'text'\n",
    "sample_df = sample_df[['target', 'text']]\n",
    "sample_df[\"target\"] = sample_df[\"target\"].apply(lambda x: 0 if x == 0 else 1)\n",
    "sample_df.to_csv('Data/raw_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4967e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X_raw = sample_df['text']\n",
    "y = sample_df['target']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_raw, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f35d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "# GloVe Twitter (par exemple 200 dimensions)\n",
    "glove_tw200 = api.load(\"glove-twitter-200\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf513957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (24711, 200)\n",
      "Words found in pretrained embeddings: 23716/24711 (95.97%)\n"
     ]
    }
   ],
   "source": [
    "## Prétraitement\n",
    "min_count = 2\n",
    "num_words = 30000\n",
    "max_len   = 50\n",
    "# Prétraitement\n",
    "X_sentence_train, tokenizer, sentences_train = preprocess_data_embedding(X_raw=X_train, \n",
    "                                                        stem_lem_func=None,\n",
    "                                                        tokenizer=None, \n",
    "                                                        stop_words=None, \n",
    "                                                        min_count=min_count,\n",
    "                                                        max_len = max_len, \n",
    "                                                        num_words=num_words, \n",
    "                                                        return_sentences=True) \n",
    "X_sentence_val = preprocess_data_embedding(X_raw=X_val, \n",
    "                                                        stem_lem_func=None,\n",
    "                                                        tokenizer=tokenizer, \n",
    "                                                        stop_words=None, \n",
    "                                                        min_count=1, # mincount = 1 car on est sur le jeu de validation\n",
    "                                                        max_len = max_len, \n",
    "                                                        num_words=num_words) \n",
    "\n",
    "\n",
    "model_vectors = glove_tw200\n",
    "latent_dim = glove_tw200.vector_size\n",
    "\n",
    "embedding_matrix, vocab_size = build_embedding_matrix(tokenizer=tokenizer,\n",
    "                                embedding_model=model_vectors, \n",
    "                                latent_dim=latent_dim\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d819ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modèle\n",
    "rnn_size = 128\n",
    "## Entrainement\n",
    "epochs = 50\n",
    "lr = 1e-3\n",
    "max_len = 50\n",
    "## Savepath des poids du modèle\n",
    "\n",
    "def rnn_layer_experiment_bi(rnn_layer_name):\n",
    "     with mlflow.start_run():\n",
    "        mlflow.log_params(params={\n",
    "            'num_words':num_words,               \n",
    "            'max_len': max_len,\n",
    "            'min_count': min_count,\n",
    "            'stemmer': 'None', \n",
    "            'latent_dim': latent_dim, \n",
    "            'rnn_size': rnn_size, \n",
    "            'epochs': epochs, \n",
    "            'learning_rate': lr,\n",
    "            'embedding_name':'Glove_twitter_200',\n",
    "            'rnn_layer_name':rnn_layer_name \n",
    "        })\n",
    "        model_savepath = \"./Models/\"+rnn_layer_name+\"_model_exp.h5\"\n",
    "        # Modèle\n",
    "\n",
    "        if rnn_layer_name=='LSTM':\n",
    "            model = build_lstm_RNN(vocab_size=vocab_size, \n",
    "                            latent_dim=latent_dim,\n",
    "                            input_length=max_len, \n",
    "                            embedding_matrix=embedding_matrix,\n",
    "                            rnn_size = rnn_size)\n",
    "        elif rnn_layer_name=='Bi-LSTM':\n",
    "            model = build_bilstm_RNN(vocab_size=vocab_size, \n",
    "                            latent_dim=latent_dim,\n",
    "                            input_length=max_len, \n",
    "                            embedding_matrix=embedding_matrix,\n",
    "                            rnn_size = rnn_size)\n",
    "\n",
    "        ## Callbacks\n",
    "        checkpoint = ModelCheckpoint(model_savepath, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min')\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
    "        lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=0, min_lr=1e-5)\n",
    "        callbacks_list = [checkpoint, es, lr_scheduler]\n",
    "        ## Compilation\n",
    "        optimizer = Adam(learning_rate=lr)\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "        #Entrainement\n",
    "        with tf.device(\"/GPU:0\"):\n",
    "            history = model.fit(X_sentence_train, y_train, epochs=epochs, batch_size=64, validation_data=(X_sentence_val,y_val), callbacks=callbacks_list, verbose=1)\n",
    "\n",
    "        model.load_weights(model_savepath)\n",
    "\n",
    "                # Prédictions sur le jeu de validation\n",
    "        y_pred_proba = model.predict(X_sentence_val)\n",
    "        y_pred = (y_pred_proba>0.5)\n",
    "\n",
    "\n",
    "        output_dict = postprocess_model_output(y_val, y_pred, y_pred_proba) # voir postprocess_data.py\n",
    "\n",
    "        # Logging des métriques dans MLflow\n",
    "        mlflow.log_metrics(output_dict)\n",
    "        # Matrice de confusion\n",
    "        cm = confusion_matrix(y_val, y_pred, normalize='pred')\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\", ax=ax, )\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"True\")\n",
    "        plt.title(\"Confusion Matrix - Validation Set\")\n",
    "        fig.savefig(\"confusion_matrix.png\")\n",
    "        plt.close(fig)\n",
    "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "        #\n",
    "        fig2 = plot_training_history(history,show=False)\n",
    "        fig2.savefig(\"learning_path.png\")\n",
    "        plt.close(fig2)\n",
    "        mlflow.log_artifact(\"learning_path.png\")\n",
    "\n",
    "        # Enregistrement du modèle dans MLflow\n",
    "        mlflow.tensorflow.log_model(model, \"model\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26e583c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 366, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 464, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1634, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1627, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment '952162272163485199'. Detailed error Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 366, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 464, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1634, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1627, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"c:\\Users\\bassm\\.conda\\envs\\AI_env_P7_gpu\\lib\\site-packages\\mlflow\\utils\\yaml_utils.py\", line 107, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Formation AI Engineer - OpenClassrooms\\Projets\\Projet 7 - Analyse de sentiments\\mlruns\\952162272163485199\\meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up MLflow experiment...\n"
     ]
    }
   ],
   "source": [
    "# Création de l'étude Optuna et optimisation\n",
    "print(\"Setting up MLflow experiment...\")\n",
    "mlflow.set_experiment(\"rnn_layer_experiment_pretrained_embedding\")\n",
    "exp_id = mlflow.get_experiment_by_name(\"rnn_layer_experiment_pretrained_embedding\").experiment_id\n",
    "\n",
    "experiment_description = (\n",
    "    \"Comparaison des impact des types de cellules RNN utilisées : SimpleRNN, GRU et LSTM \"\n",
    "    \"\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that\n",
    "# will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"Sentiment analysis modelling\",\n",
    "    \"model_type\": \"RNN_types-pretrained-embeddings\",\n",
    "    \"team\": \"Ph. Constant\",\n",
    "    \"project_quarter\": \"Q3-2025\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "for key, value in experiment_tags.items():\n",
    "    client.set_experiment_tag(exp_id, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d25b3f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test with Bi-LSTM\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 50, 200)           4942200   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 50, 256)          336896    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 256)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                16448     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,295,609\n",
      "Trainable params: 353,409\n",
      "Non-trainable params: 4,942,200\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 467s 232ms/step - loss: 0.4829 - accuracy: 0.7665 - val_loss: 0.4374 - val_accuracy: 0.7970 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 498s 249ms/step - loss: 0.4427 - accuracy: 0.7921 - val_loss: 0.4225 - val_accuracy: 0.8035 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 514s 257ms/step - loss: 0.4275 - accuracy: 0.8010 - val_loss: 0.4129 - val_accuracy: 0.8101 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 507s 253ms/step - loss: 0.4156 - accuracy: 0.8083 - val_loss: 0.4128 - val_accuracy: 0.8123 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 447s 223ms/step - loss: 0.4068 - accuracy: 0.8131 - val_loss: 0.4076 - val_accuracy: 0.8101 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 511s 255ms/step - loss: 0.3975 - accuracy: 0.8179 - val_loss: 0.4010 - val_accuracy: 0.8169 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 523s 261ms/step - loss: 0.3897 - accuracy: 0.8217 - val_loss: 0.3985 - val_accuracy: 0.8174 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 516s 258ms/step - loss: 0.3825 - accuracy: 0.8264 - val_loss: 0.3995 - val_accuracy: 0.8191 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 518s 259ms/step - loss: 0.3785 - accuracy: 0.8280 - val_loss: 0.4006 - val_accuracy: 0.8191 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 528s 264ms/step - loss: 0.3652 - accuracy: 0.8343 - val_loss: 0.4032 - val_accuracy: 0.8201 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 528s 264ms/step - loss: 0.3599 - accuracy: 0.8366 - val_loss: 0.3969 - val_accuracy: 0.8207 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 554s 277ms/step - loss: 0.3541 - accuracy: 0.8396 - val_loss: 0.3982 - val_accuracy: 0.8211 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 558s 279ms/step - loss: 0.3517 - accuracy: 0.8422 - val_loss: 0.4028 - val_accuracy: 0.8213 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 436s 218ms/step - loss: 0.3434 - accuracy: 0.8450 - val_loss: 0.4046 - val_accuracy: 0.8208 - lr: 2.5000e-04\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 382s 191ms/step - loss: 0.3406 - accuracy: 0.8475 - val_loss: 0.4035 - val_accuracy: 0.8212 - lr: 2.5000e-04\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 385s 192ms/step - loss: 0.3354 - accuracy: 0.8495 - val_loss: 0.4090 - val_accuracy: 0.8216 - lr: 1.2500e-04\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 385s 193ms/step - loss: 0.3343 - accuracy: 0.8514 - val_loss: 0.4090 - val_accuracy: 0.8207 - lr: 1.2500e-04\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 384s 192ms/step - loss: 0.3322 - accuracy: 0.8521 - val_loss: 0.4082 - val_accuracy: 0.8217 - lr: 6.2500e-05\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 385s 193ms/step - loss: 0.3319 - accuracy: 0.8517 - val_loss: 0.4077 - val_accuracy: 0.8225 - lr: 6.2500e-05\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 383s 191ms/step - loss: 0.3296 - accuracy: 0.8526 - val_loss: 0.4108 - val_accuracy: 0.8214 - lr: 3.1250e-05\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 384s 192ms/step - loss: 0.3289 - accuracy: 0.8535 - val_loss: 0.4102 - val_accuracy: 0.8211 - lr: 3.1250e-05\n",
      "1000/1000 [==============================] - 46s 46ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/19 03:17:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/19 03:17:55 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp6ziokbj2\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\bassm\\AppData\\Local\\Temp\\tmp6ziokbj2\\model\\data\\model\\assets\n",
      "2025/09/19 03:18:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Running test with Bi-LSTM\")\n",
    "rnn_layer_experiment_bi(\"Bi-LSTM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4310e0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_env_P7_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
